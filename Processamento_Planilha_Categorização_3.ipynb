{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python386jvsc74a57bd0c9037d6a239f88f5dd1ffc6bf2fe80bb7a6b1100bd95b854bbbb5680e50c96da",
      "display_name": "Python 3.8.6 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "c9037d6a239f88f5dd1ffc6bf2fe80bb7a6b1100bd95b854bbbb5680e50c96da"
      }
    },
    "colab": {
      "name": "Processamento Planilha Categorização_3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsxxG43hHUAc"
      },
      "source": [
        "## Métodos de Machine Learning para a classificação da planilha de oportunidades em texto\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y0_jGiOHUAf"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpmI6VHgHUAg"
      },
      "source": [
        "arq = r\"C:\\Users\\bolin\\Desktop\\codigos\\mcti-sefip-ppfcd2020\\oportunidades_classificacao_3.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wEFQ1VFHUAg"
      },
      "source": [
        "df = pd.read_excel(arq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi5jowwj5kjI"
      },
      "source": [
        "Leitura e primeiras observações do Dataframe correspondente à planilha de oportunidades:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSpUBsaRHUAg",
        "outputId": "b8a300ff-b072-4ce5-93f2-834725e68847"
      },
      "source": [
        "df.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          opo_titulo  \\\n",
              "0     Knowledge Product to Strengthen Women's Voices   \n",
              "1  Bolsas de PD em Política Científica e Tecnológica   \n",
              "2                 Bolsa de TT-II em Ciência de Dados   \n",
              "3       Bolsa de PD em História da Filosofia Moderna   \n",
              "\n",
              "                                                link opo_brazil  \\\n",
              "0  https://www.cepf.net/grants/open-calls-for-pro...          N   \n",
              "1  http://fapesp.br/oportunidades/Control/../inov...          Y   \n",
              "2  http://fapesp.br/oportunidades/Control/../fish...          Y   \n",
              "3  http://fapesp.br/oportunidades/Control/../pode...          Y   \n",
              "\n",
              "    opo_deadline               codigo  \\\n",
              "0  30 April 2021   cepf_210429_01_000   \n",
              "1     30/04/2021  fapesp_210429_1_000   \n",
              "2     30/04/2021  fapesp_210429_1_001   \n",
              "3     30/04/2021  fapesp_210429_1_002   \n",
              "\n",
              "                                           opo_texto  \\\n",
              "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
              "1  Unicamp's Department of Scientific and Technol...   \n",
              "2  The vacancy is for graduates of a Technical Co...   \n",
              "3  The scholarship lasts for two years and can be...   \n",
              "\n",
              "                                       opo_texto_ele     opo_tipo  \\\n",
              "0   gender-cfp-2021.jpg Caption: Interviewing a c...        other   \n",
              "1  Unicamp's Department of Scientific and Technol...  scholarship   \n",
              "2  The vacancy is for graduates of a Technical Co...  scholarship   \n",
              "3  The scholarship lasts for two years and can be...  scholarship   \n",
              "\n",
              "   atualizacao clas comentario  \n",
              "0       210429    N        NaN  \n",
              "1       210429    Y        NaN  \n",
              "2       210429    Y        NaN  \n",
              "3       210429    Y        NaN  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_titulo</th>\n",
              "      <th>link</th>\n",
              "      <th>opo_brazil</th>\n",
              "      <th>opo_deadline</th>\n",
              "      <th>codigo</th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_ele</th>\n",
              "      <th>opo_tipo</th>\n",
              "      <th>atualizacao</th>\n",
              "      <th>clas</th>\n",
              "      <th>comentario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Knowledge Product to Strengthen Women's Voices</td>\n",
              "      <td>https://www.cepf.net/grants/open-calls-for-pro...</td>\n",
              "      <td>N</td>\n",
              "      <td>30 April 2021</td>\n",
              "      <td>cepf_210429_01_000</td>\n",
              "      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n",
              "      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n",
              "      <td>other</td>\n",
              "      <td>210429</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bolsas de PD em Política Científica e Tecnológica</td>\n",
              "      <td>http://fapesp.br/oportunidades/Control/../inov...</td>\n",
              "      <td>Y</td>\n",
              "      <td>30/04/2021</td>\n",
              "      <td>fapesp_210429_1_000</td>\n",
              "      <td>Unicamp's Department of Scientific and Technol...</td>\n",
              "      <td>Unicamp's Department of Scientific and Technol...</td>\n",
              "      <td>scholarship</td>\n",
              "      <td>210429</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bolsa de TT-II em Ciência de Dados</td>\n",
              "      <td>http://fapesp.br/oportunidades/Control/../fish...</td>\n",
              "      <td>Y</td>\n",
              "      <td>30/04/2021</td>\n",
              "      <td>fapesp_210429_1_001</td>\n",
              "      <td>The vacancy is for graduates of a Technical Co...</td>\n",
              "      <td>The vacancy is for graduates of a Technical Co...</td>\n",
              "      <td>scholarship</td>\n",
              "      <td>210429</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bolsa de PD em História da Filosofia Moderna</td>\n",
              "      <td>http://fapesp.br/oportunidades/Control/../pode...</td>\n",
              "      <td>Y</td>\n",
              "      <td>30/04/2021</td>\n",
              "      <td>fapesp_210429_1_002</td>\n",
              "      <td>The scholarship lasts for two years and can be...</td>\n",
              "      <td>The scholarship lasts for two years and can be...</td>\n",
              "      <td>scholarship</td>\n",
              "      <td>210429</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YokPhhSTHUAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ0UJKPXHUAi"
      },
      "source": [
        "### Variáveis de interesse\n",
        "\n",
        "Aqui queremos as variáveis 'opo_texto': Texto referente à cada oportunidade e 'clas': variável binária que diz se a oportunidade é elegível ou não"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "s1NNfLdhHUAi"
      },
      "source": [
        "# Coleta das variáveis de interesse\n",
        "X = df[['opo_texto']].copy()\n",
        "y = df[['clas']].copy()\n",
        "# y = [re.sub(\" \",\"\",i) for i in str(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cah0V7EHUAj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Q_5WyVHUAj"
      },
      "source": [
        "## Pré-processamento\n",
        "\n",
        "Essa classe é definida para tratar os textos e realizar algumas limpezas, como a remoção de caracteres não alfa numéricos, caracteres especias, separar palavras coladas, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M287HFRjHUAj"
      },
      "source": [
        "class Sentenca():\n",
        "\n",
        "    def __init__(self, sentenca):\n",
        "        self.sent_bruta = sentenca\n",
        "        self.preproc()\n",
        "    \n",
        "    def remove_caracteres_nao_alfanumericos(self):\n",
        "        # padroes para trechos nao alfanumericos\n",
        "        ptn_nao_alfanum = r\"[\\W+]\"\n",
        "        self.sent_preproc = re.sub(ptn_nao_alfanum, ' ', self.sent_bruta)\n",
        "\n",
        "    def remove_a_chapeu(self):\n",
        "        # padroes para trechos nao alfanumericos\n",
        "        ptn_nao_chap = r\"(Â|â|œ)\"\n",
        "        self.sent_preproc = re.sub(ptn_nao_chap, ' ', self.sent_preproc)\n",
        "    \n",
        "    def remove_espacos_multiplos(self):\n",
        "        ptn_espacos_mult = r\"\\s+\"  \n",
        "        self.sent_preproc = re.sub(ptn_espacos_mult, ' ', self.sent_preproc)\n",
        "        self.sent_preproc = self.sent_preproc.strip()\n",
        "    \n",
        "    def remove_b_inicial(self):\n",
        "        if self.sent_preproc.startswith('b '):\n",
        "            self.sent_preproc = self.sent_preproc[2:]\n",
        "    \n",
        "    def separa_palavras_coladas(self):\n",
        "        \"\"\"Separa com espaço palavras coladas, aqui definido quando uma letra \n",
        "        minúscula está colada com uma maiúscula imediatalmente posterior\"\"\"\n",
        "        ptn_ltr_minusc_colada_maiuscula = r'([a-z])([A-Z])'\n",
        "        ptn_algarismo_colado_maiuscula = r'([0-9])([A-Z])'\n",
        "        \n",
        "        self.sent_preproc = re.sub(ptn_ltr_minusc_colada_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
        "        self.sent_preproc = re.sub(ptn_algarismo_colado_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
        "    \n",
        "    def preproc(self):\n",
        "        self.sent_preproc = ''\n",
        "        self.remove_caracteres_nao_alfanumericos()\n",
        "        self.remove_a_chapeu()\n",
        "        self.remove_espacos_multiplos()\n",
        "        self.remove_b_inicial()\n",
        "        self.separa_palavras_coladas()\n",
        "        self.sent_preproc = self.sent_preproc.lower()\n",
        "        \n",
        "        return self.sent_preproc\n",
        "    \n",
        "    def __getitem__(self, indices):\n",
        "        return ''.join(self.sent_preproc[indices])\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.sent_preproc)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.sent_preproc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rra5APdrHUAk"
      },
      "source": [
        "X['opo_texto_preproc'] = X['opo_texto'].apply(Sentenca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8vmomDC6ky_"
      },
      "source": [
        "Aqui podemos ver como o primeiro texto ficou após receber o tratamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD19UlyIHUAk",
        "outputId": "d335e238-f517-4bd4-ce5a-1dba7390a154"
      },
      "source": [
        "X['opo_texto_preproc'].iloc[0][:306]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gender cfp 2021 jpg caption interviewing a community member in lao pdr credit fishbio call for proposals development of an innovative knowledge product pertaining to the strengthening of women s voices in conservation opening date 22 march 2021 closing date 30 april 2021 questions due date 15 april 2021 s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkjjlMjHUAk",
        "outputId": "3c62afe3-21a1-4ec6-c15d-4fc7db34e32b"
      },
      "source": [
        "X.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           opo_texto  \\\n",
              "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
              "1  Unicamp's Department of Scientific and Technol...   \n",
              "2  The vacancy is for graduates of a Technical Co...   \n",
              "3  The scholarship lasts for two years and can be...   \n",
              "\n",
              "                                   opo_texto_preproc  \n",
              "0  gender cfp 2021 jpg caption interviewing a com...  \n",
              "1  unicamp s department of scientific and technol...  \n",
              "2  the vacancy is for graduates of a technical co...  \n",
              "3  the scholarship lasts for two years and can be...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n",
              "      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unicamp's Department of Scientific and Technol...</td>\n",
              "      <td>unicamp s department of scientific and technol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The vacancy is for graduates of a Technical Co...</td>\n",
              "      <td>the vacancy is for graduates of a technical co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The scholarship lasts for two years and can be...</td>\n",
              "      <td>the scholarship lasts for two years and can be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvITjfSu9JLe"
      },
      "source": [
        "Apesar do pré processamento feito com a classe Sentença, ainda existem algumas *strings* sem sentido. Assim, é comparado as palavras com o dicionário em inglês e mantendo apenas as palavras existentes no dicionário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "j01GM0SbHUAl",
        "outputId": "cdf7766c-e2a5-4297-d371-46decccd690b"
      },
      "source": [
        "lista_texto = X['opo_texto_preproc'].tolist()\n",
        "lista_texto = [str(i) for i in lista_texto]\n",
        "# print(type((lista_texto[0])))\n",
        "values = ','.join(str(v) for v in lista_texto)\n",
        "unique_words = set(values.split(' '))\n",
        "unique_words = sorted(unique_words)\n",
        "\n",
        "import enchant # pip install pyenchant\n",
        "def frase_dicionario(frase):\n",
        "    d = enchant.Dict(\"en_GB\")\n",
        "    jus = frase.split(' ')\n",
        "    lista_frase_dic = [i for i in jus if d.check(i)]\n",
        "    frase_final = ' '.join(lista_frase_dic)\n",
        "    return(frase_final)\n",
        "\n",
        "opo_texto_dicio=[]\n",
        "for i in lista_texto: # não funcionou com listcompreension\n",
        "    opo_texto_dicio.append(frase_dicionario(i))\n",
        "\n",
        "X['opo_texto_dicio'] = opo_texto_dicio\n",
        "X.head(4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           opo_texto  \\\n",
              "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
              "1  Unicamp's Department of Scientific and Technol...   \n",
              "2  The vacancy is for graduates of a Technical Co...   \n",
              "3  The scholarship lasts for two years and can be...   \n",
              "\n",
              "                                   opo_texto_preproc  \\\n",
              "0  gender cfp 2021 jpg caption interviewing a com...   \n",
              "1  unicamp s department of scientific and technol...   \n",
              "2  the vacancy is for graduates of a technical co...   \n",
              "3  the scholarship lasts for two years and can be...   \n",
              "\n",
              "                                     opo_texto_dicio  \n",
              "0  gender 2021 caption interviewing a community m...  \n",
              "1  s department of scientific and technological p...  \n",
              "2  the vacancy is for graduates of a technical co...  \n",
              "3  the scholarship lasts for two years and can be...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_preproc</th>\n",
              "      <th>opo_texto_dicio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n",
              "      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n",
              "      <td>gender 2021 caption interviewing a community m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unicamp's Department of Scientific and Technol...</td>\n",
              "      <td>unicamp s department of scientific and technol...</td>\n",
              "      <td>s department of scientific and technological p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The vacancy is for graduates of a Technical Co...</td>\n",
              "      <td>the vacancy is for graduates of a technical co...</td>\n",
              "      <td>the vacancy is for graduates of a technical co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The scholarship lasts for two years and can be...</td>\n",
              "      <td>the scholarship lasts for two years and can be...</td>\n",
              "      <td>the scholarship lasts for two years and can be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh7XJtUG907g"
      },
      "source": [
        "As chamadas *Stopwords* são palavras que podem ser consideradas irrelevantes para o conjunto de texto, são palavras de conexão. O módulo *NLTK* possui uma biblioteca específica para remover as stopwords:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsvhY9jBHUAl"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_z5LJEsHUAl"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBc0quO0HUAm"
      },
      "source": [
        "stop_ingles = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxtmG6tQHUAm"
      },
      "source": [
        "def remove_stopwords(sentenca):\n",
        "    tokens = str(sentenca).split(' ')\n",
        "    tokens_sem_stops = [token for token in tokens if token not in stop_ingles]\n",
        "    return ' '.join(tokens_sem_stops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDl_XCAHUAm"
      },
      "source": [
        "# Troquei aqui para o dicio \n",
        "X['opo_texto_sem_stop'] = X['opo_texto_dicio'].apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stu9wNkAHUAm",
        "outputId": "9e9e1f06-7555-4078-8fb3-456d3f765e37"
      },
      "source": [
        "X.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           opo_texto  \\\n",
              "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
              "1  Unicamp's Department of Scientific and Technol...   \n",
              "2  The vacancy is for graduates of a Technical Co...   \n",
              "3  The scholarship lasts for two years and can be...   \n",
              "\n",
              "                                   opo_texto_preproc  \\\n",
              "0  gender cfp 2021 jpg caption interviewing a com...   \n",
              "1  unicamp s department of scientific and technol...   \n",
              "2  the vacancy is for graduates of a technical co...   \n",
              "3  the scholarship lasts for two years and can be...   \n",
              "\n",
              "                                     opo_texto_dicio  \\\n",
              "0  gender 2021 caption interviewing a community m...   \n",
              "1  s department of scientific and technological p...   \n",
              "2  the vacancy is for graduates of a technical co...   \n",
              "3  the scholarship lasts for two years and can be...   \n",
              "\n",
              "                                  opo_texto_sem_stop  \n",
              "0  gender 2021 caption interviewing community mem...  \n",
              "1  department scientific technological policy por...  \n",
              "2  vacancy graduates technical course student las...  \n",
              "3  scholarship lasts two years renewed another ye...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_preproc</th>\n",
              "      <th>opo_texto_dicio</th>\n",
              "      <th>opo_texto_sem_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n",
              "      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n",
              "      <td>gender 2021 caption interviewing a community m...</td>\n",
              "      <td>gender 2021 caption interviewing community mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unicamp's Department of Scientific and Technol...</td>\n",
              "      <td>unicamp s department of scientific and technol...</td>\n",
              "      <td>s department of scientific and technological p...</td>\n",
              "      <td>department scientific technological policy por...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The vacancy is for graduates of a Technical Co...</td>\n",
              "      <td>the vacancy is for graduates of a technical co...</td>\n",
              "      <td>the vacancy is for graduates of a technical co...</td>\n",
              "      <td>vacancy graduates technical course student las...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The scholarship lasts for two years and can be...</td>\n",
              "      <td>the scholarship lasts for two years and can be...</td>\n",
              "      <td>the scholarship lasts for two years and can be...</td>\n",
              "      <td>scholarship lasts two years renewed another ye...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_ZqvtdBMHUAn",
        "outputId": "b6b20e33-c808-4516-e174-1dadb6688c68"
      },
      "source": [
        "print(X['opo_texto_sem_stop'][0][:302], '\\n...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender 2021 caption interviewing community member credit call proposals development innovative knowledge product pertaining strengthening women voices conservation opening date 22 march 2021 closing date 30 2021 questions due date 15 2021 submissions applications sent net closing date overview intends \n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tou9x_b6HUAn"
      },
      "source": [
        "## Tokenização\n",
        "\n",
        "O processo de “quebrar ” o texto em unidades menores é chamado de Tokenização, sendo os tokens as únidades mínimas em que o texto pode ser fragmentado. Essas unidades são representadas por um vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiF55eEXHUAn"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZIr7DMkHUAo"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uobtytAtHUAo"
      },
      "source": [
        "X['opo_texto_tokens'] = X['opo_texto_sem_stop'].apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqpE9iLXHUAo",
        "outputId": "0d0c712a-6507-45fb-d18e-b909e0d2e72c"
      },
      "source": [
        "print(X['opo_texto_tokens'].iloc[0][:50], '\\n...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gender', '2021', 'caption', 'interviewing', 'community', 'member', 'credit', 'call', 'proposals', 'development', 'innovative', 'knowledge', 'product', 'pertaining', 'strengthening', 'women', 'voices', 'conservation', 'opening', 'date', '22', 'march', '2021', 'closing', 'date', '30', '2021', 'questions', 'due', 'date', '15', '2021', 'submissions', 'applications', 'sent', 'net', 'closing', 'date', 'overview', 'intends', 'engage', 'consultant', 'develop', 'knowledge', 'product', 'provide', 'guidance', 'strengthen', 'women', 'voices'] \n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etCa5Ml6HUAo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvvzKr1tHUAo"
      },
      "source": [
        "## Lematização\n",
        "\n",
        "A lematização é útil quando queremos ver os usos de palavras em contextos sem importância das flexões. Por exemplo, para a criação e uso de índices ou na investigação linguística. Desse modo, palavras como \"*grant*\" e \"*grants*\" se tornam uma só e aliadas à tokenização, correspondem ao mesmo *token* no vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk6wXl4sHUAp"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmUF8hkOHUAp"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqQN06c5HUAp"
      },
      "source": [
        "wordnet = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMcFaf9lHUAp"
      },
      "source": [
        "def lematiza_tokens(tokens):\n",
        "    return [wordnet.lemmatize(token) for token in tokens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiqaFHtWHUAp"
      },
      "source": [
        "# lematização dos tokens\n",
        "X['opo_texto_tokens_lem'] = X['opo_texto_tokens'].apply(lematiza_tokens)\n",
        "X['opo_texto_sem_stop_lem'] = X['opo_texto_tokens_lem'].apply(lambda l: ' '.join(l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y4Gx4dxHUAq"
      },
      "source": [
        "### Tokenização e Lematização:\n",
        "Podemos ver então como ficam os textos em cada um desses processos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2TDekwG_HUAq",
        "outputId": "2c01b433-efd2-4f3c-819b-ba2c2337928a"
      },
      "source": [
        "X[['opo_texto_tokens', 'opo_texto_tokens_lem', 'opo_texto_sem_stop_lem']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    opo_texto_tokens  \\\n",
              "0  [gender, 2021, caption, interviewing, communit...   \n",
              "1  [department, scientific, technological, policy...   \n",
              "2  [vacancy, graduates, technical, course, studen...   \n",
              "3  [scholarship, lasts, two, years, renewed, anot...   \n",
              "4  [registration, open, selection, one, 01, schol...   \n",
              "5  [technical, training, scholarship, level, iv, ...   \n",
              "6  [candidate, desired, skills, experience, molec...   \n",
              "7  [prerequisites, graduation, biology, zootechni...   \n",
              "8  [consultancy, specialized, application, develo...   \n",
              "9  [collaborative, project, within, department, b...   \n",
              "\n",
              "                                opo_texto_tokens_lem  \\\n",
              "0  [gender, 2021, caption, interviewing, communit...   \n",
              "1  [department, scientific, technological, policy...   \n",
              "2  [vacancy, graduate, technical, course, student...   \n",
              "3  [scholarship, last, two, year, renewed, anothe...   \n",
              "4  [registration, open, selection, one, 01, schol...   \n",
              "5  [technical, training, scholarship, level, iv, ...   \n",
              "6  [candidate, desired, skill, experience, molecu...   \n",
              "7  [prerequisite, graduation, biology, zootechnic...   \n",
              "8  [consultancy, specialized, application, develo...   \n",
              "9  [collaborative, project, within, department, b...   \n",
              "\n",
              "                              opo_texto_sem_stop_lem  \n",
              "0  gender 2021 caption interviewing community mem...  \n",
              "1  department scientific technological policy por...  \n",
              "2  vacancy graduate technical course student last...  \n",
              "3  scholarship last two year renewed another year...  \n",
              "4  registration open selection one 01 scholarship...  \n",
              "5  technical training scholarship level iv iv ava...  \n",
              "6  candidate desired skill experience molecular b...  \n",
              "7  prerequisite graduation biology zootechnics fi...  \n",
              "8  consultancy specialized application developmen...  \n",
              "9  collaborative project within department bioche...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto_tokens</th>\n",
              "      <th>opo_texto_tokens_lem</th>\n",
              "      <th>opo_texto_sem_stop_lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[gender, 2021, caption, interviewing, communit...</td>\n",
              "      <td>[gender, 2021, caption, interviewing, communit...</td>\n",
              "      <td>gender 2021 caption interviewing community mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[department, scientific, technological, policy...</td>\n",
              "      <td>[department, scientific, technological, policy...</td>\n",
              "      <td>department scientific technological policy por...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[vacancy, graduates, technical, course, studen...</td>\n",
              "      <td>[vacancy, graduate, technical, course, student...</td>\n",
              "      <td>vacancy graduate technical course student last...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n",
              "      <td>[scholarship, last, two, year, renewed, anothe...</td>\n",
              "      <td>scholarship last two year renewed another year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[registration, open, selection, one, 01, schol...</td>\n",
              "      <td>[registration, open, selection, one, 01, schol...</td>\n",
              "      <td>registration open selection one 01 scholarship...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[technical, training, scholarship, level, iv, ...</td>\n",
              "      <td>[technical, training, scholarship, level, iv, ...</td>\n",
              "      <td>technical training scholarship level iv iv ava...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[candidate, desired, skills, experience, molec...</td>\n",
              "      <td>[candidate, desired, skill, experience, molecu...</td>\n",
              "      <td>candidate desired skill experience molecular b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[prerequisites, graduation, biology, zootechni...</td>\n",
              "      <td>[prerequisite, graduation, biology, zootechnic...</td>\n",
              "      <td>prerequisite graduation biology zootechnics fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[consultancy, specialized, application, develo...</td>\n",
              "      <td>[consultancy, specialized, application, develo...</td>\n",
              "      <td>consultancy specialized application developmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[collaborative, project, within, department, b...</td>\n",
              "      <td>[collaborative, project, within, department, b...</td>\n",
              "      <td>collaborative project within department bioche...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTphq8_hHUAq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1pXePBJHUAr"
      },
      "source": [
        "## Bag of Words\n",
        "O BoW nada mais é que uma coleção de palavras representadas por uma contagem que desconsidera a ordem em que as palavras aparecem em cada texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SXVWOqVHUAr"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfS6nH26HUAr"
      },
      "source": [
        "X['opo_texto_bow'] = X['opo_texto_tokens'].apply(Counter)\n",
        "X['opo_texto_bow_lem'] = X['opo_texto_tokens_lem'].apply(Counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCReXeV0HUAr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSQp7MuRHUAr"
      },
      "source": [
        "Bag of words com e sem lematização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Z5epcI-sHUAr",
        "outputId": "04042261-2d9b-4d33-8180-0a0a55e1b1b9"
      },
      "source": [
        "X[['opo_texto_tokens', 'opo_texto_bow', 'opo_texto_bow_lem']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    opo_texto_tokens  \\\n",
              "0  [gender, 2021, caption, interviewing, communit...   \n",
              "1  [department, scientific, technological, policy...   \n",
              "2  [vacancy, graduates, technical, course, studen...   \n",
              "3  [scholarship, lasts, two, years, renewed, anot...   \n",
              "4  [registration, open, selection, one, 01, schol...   \n",
              "5  [technical, training, scholarship, level, iv, ...   \n",
              "6  [candidate, desired, skills, experience, molec...   \n",
              "7  [prerequisites, graduation, biology, zootechni...   \n",
              "8  [consultancy, specialized, application, develo...   \n",
              "9  [collaborative, project, within, department, b...   \n",
              "\n",
              "                                       opo_texto_bow  \\\n",
              "0  {'gender': 1, '2021': 4, 'caption': 1, 'interv...   \n",
              "1  {'department': 1, 'scientific': 1, 'technologi...   \n",
              "2  {'vacancy': 1, 'graduates': 1, 'technical': 1,...   \n",
              "3  {'scholarship': 4, 'lasts': 1, 'two': 1, 'year...   \n",
              "4  {'registration': 2, 'open': 1, 'selection': 1,...   \n",
              "5  {'technical': 1, 'training': 1, 'scholarship':...   \n",
              "6  {'candidate': 1, 'desired': 2, 'skills': 1, 'e...   \n",
              "7  {'prerequisites': 1, 'graduation': 1, 'biology...   \n",
              "8  {'consultancy': 1, 'specialized': 1, 'applicat...   \n",
              "9  {'collaborative': 1, 'project': 1, 'within': 1...   \n",
              "\n",
              "                                   opo_texto_bow_lem  \n",
              "0  {'gender': 1, '2021': 4, 'caption': 1, 'interv...  \n",
              "1  {'department': 1, 'scientific': 1, 'technologi...  \n",
              "2  {'vacancy': 1, 'graduate': 1, 'technical': 1, ...  \n",
              "3  {'scholarship': 4, 'last': 1, 'two': 1, 'year'...  \n",
              "4  {'registration': 3, 'open': 1, 'selection': 1,...  \n",
              "5  {'technical': 1, 'training': 1, 'scholarship':...  \n",
              "6  {'candidate': 1, 'desired': 2, 'skill': 1, 'ex...  \n",
              "7  {'prerequisite': 1, 'graduation': 1, 'biology'...  \n",
              "8  {'consultancy': 1, 'specialized': 1, 'applicat...  \n",
              "9  {'collaborative': 1, 'project': 1, 'within': 1...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto_tokens</th>\n",
              "      <th>opo_texto_bow</th>\n",
              "      <th>opo_texto_bow_lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[gender, 2021, caption, interviewing, communit...</td>\n",
              "      <td>{'gender': 1, '2021': 4, 'caption': 1, 'interv...</td>\n",
              "      <td>{'gender': 1, '2021': 4, 'caption': 1, 'interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[department, scientific, technological, policy...</td>\n",
              "      <td>{'department': 1, 'scientific': 1, 'technologi...</td>\n",
              "      <td>{'department': 1, 'scientific': 1, 'technologi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[vacancy, graduates, technical, course, studen...</td>\n",
              "      <td>{'vacancy': 1, 'graduates': 1, 'technical': 1,...</td>\n",
              "      <td>{'vacancy': 1, 'graduate': 1, 'technical': 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n",
              "      <td>{'scholarship': 4, 'lasts': 1, 'two': 1, 'year...</td>\n",
              "      <td>{'scholarship': 4, 'last': 1, 'two': 1, 'year'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[registration, open, selection, one, 01, schol...</td>\n",
              "      <td>{'registration': 2, 'open': 1, 'selection': 1,...</td>\n",
              "      <td>{'registration': 3, 'open': 1, 'selection': 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[technical, training, scholarship, level, iv, ...</td>\n",
              "      <td>{'technical': 1, 'training': 1, 'scholarship':...</td>\n",
              "      <td>{'technical': 1, 'training': 1, 'scholarship':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[candidate, desired, skills, experience, molec...</td>\n",
              "      <td>{'candidate': 1, 'desired': 2, 'skills': 1, 'e...</td>\n",
              "      <td>{'candidate': 1, 'desired': 2, 'skill': 1, 'ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[prerequisites, graduation, biology, zootechni...</td>\n",
              "      <td>{'prerequisites': 1, 'graduation': 1, 'biology...</td>\n",
              "      <td>{'prerequisite': 1, 'graduation': 1, 'biology'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[consultancy, specialized, application, develo...</td>\n",
              "      <td>{'consultancy': 1, 'specialized': 1, 'applicat...</td>\n",
              "      <td>{'consultancy': 1, 'specialized': 1, 'applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[collaborative, project, within, department, b...</td>\n",
              "      <td>{'collaborative': 1, 'project': 1, 'within': 1...</td>\n",
              "      <td>{'collaborative': 1, 'project': 1, 'within': 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxH4qyCmHUAs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QECZUjtBHUAs"
      },
      "source": [
        "### Mapeamento do Corpus em Dicionário"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crOgFUODHUAs"
      },
      "source": [
        "Vamos passar a usar números para representar cada token, por meio da criação de um `dicionario_corpus`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du3n6yceHUAs"
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "s2uoUo4bHUAs"
      },
      "source": [
        "dicionario_corpus = Dictionary(X['opo_texto_tokens'].tolist() + X['opo_texto_tokens_lem'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umyVAXE9HUAt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18vJd0IuHUAt"
      },
      "source": [
        "Resultado do mapeamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kecF63eHUAt",
        "outputId": "0abc779e-1f95-4a7a-92e5-c7d8b38c4b26"
      },
      "source": [
        "print('Dicionario do corpus:\\n\\n',\n",
        "      {k: v for i, (k, v) in enumerate(dicionario_corpus.token2id.items()) if i < 80}, '\\n...', sep='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dicionario do corpus:\n",
            "\n",
            "{'15': 0, '2021': 1, '22': 2, '238': 3, '30': 4, 'applications': 5, 'call': 6, 'caption': 7, 'closing': 8, 'community': 9, 'conservation': 10, 'consultant': 11, 'credit': 12, 'date': 13, 'develop': 14, 'development': 15, 'due': 16, 'engage': 17, 'english': 18, 'gender': 19, 'guidance': 20, 'information': 21, 'innovative': 22, 'intends': 23, 'interviewing': 24, 'kb': 25, 'knowledge': 26, 'march': 27, 'member': 28, 'net': 29, 'opening': 30, 'overview': 31, 'pertaining': 32, 'product': 33, 'proposals': 34, 'provide': 35, 'questions': 36, 'sent': 37, 'strengthen': 38, 'strengthening': 39, 'submissions': 40, 'voices': 41, 'women': 42, '1': 43, '10': 44, '2': 45, '202': 46, '3': 47, '373': 48, '378': 49, '4': 50, '5': 51, '553': 52, '6230': 53, '7': 54, 'activity': 55, 'amount': 56, 'announces': 57, 'annual': 58, 'application': 59, 'available': 60, 'based': 61, 'big': 62, 'br': 63, 'calls': 64, 'catching': 65, 'chair': 66, 'communicate': 67, 'contact': 68, 'convergence': 69, 'data': 70, 'department': 71, 'design': 72, 'directly': 73, 'doctoral': 74, 'ecosystems': 75, 'electronically': 76, 'email': 77, 'en': 78, 'entrepreneurship': 79}\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dVsxtZIHUAt"
      },
      "source": [
        "Exemplo de consulta ao dicionário:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kYxldaCFHUAt",
        "outputId": "0adf0415-9c84-4fec-9d4d-b7e489deb359"
      },
      "source": [
        "dicionario_corpus.token2id['grant']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mEzHmArHUAu"
      },
      "source": [
        "### Bag of Words com Dicionário"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_4lEbrKHUAu"
      },
      "source": [
        "Vamos criar duas novas colunas fazendo `bag of words` de pares de inteiros para o texto normal e para o lematizado.\n",
        "O primeiro elemento deste par é o `id` do token no `dicionario_corpus` e o segundo elemento é a contagem de ocorrências deste token no documento.\n",
        "\n",
        "Estamos convencionando chamar as colunas inteiras de `'opo_int_...'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjnXjuftHUAu"
      },
      "source": [
        "# Criação dos bag of words para o texto normal e lematizado\n",
        "X['opo_int_bow'] = X['opo_texto_tokens'].apply(dicionario_corpus.doc2bow)\n",
        "X['opo_int_bow_lem'] = X['opo_texto_tokens_lem'].apply(dicionario_corpus.doc2bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R661p8JCHUAu"
      },
      "source": [
        "Resultado dos bag of words após mapeamento em dicionário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoojfYPrHUAv",
        "outputId": "9c37b7f8-d8a3-4d1b-e47c-a85fa84ee90c"
      },
      "source": [
        "X[['opo_texto_tokens', 'opo_int_bow', 'opo_int_bow_lem']].head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     opo_texto_tokens  \\\n",
              "0   [gender, 2021, caption, interviewing, communit...   \n",
              "1   [department, scientific, technological, policy...   \n",
              "2   [vacancy, graduates, technical, course, studen...   \n",
              "3   [scholarship, lasts, two, years, renewed, anot...   \n",
              "4   [registration, open, selection, one, 01, schol...   \n",
              "5   [technical, training, scholarship, level, iv, ...   \n",
              "6   [candidate, desired, skills, experience, molec...   \n",
              "7   [prerequisites, graduation, biology, zootechni...   \n",
              "8   [consultancy, specialized, application, develo...   \n",
              "9   [collaborative, project, within, department, b...   \n",
              "10  [multi, structural, crystallography, laborator...   \n",
              "11  [vacancy, postdoctoral, researcher, code, scho...   \n",
              "12  [opportunity, 1, level, three, technical, trai...   \n",
              "13  [research, innovation, biodiversity, pharmaceu...   \n",
              "14  [research, innovation, biodiversity, pharmaceu...   \n",
              "\n",
              "                                          opo_int_bow  \\\n",
              "0   [(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1...   \n",
              "1   [(1, 1), (6, 1), (21, 1), (43, 2), (44, 2), (4...   \n",
              "2   [(15, 1), (21, 2), (61, 3), (63, 1), (70, 2), ...   \n",
              "3   [(44, 3), (48, 1), (54, 1), (55, 1), (56, 1), ...   \n",
              "4   [(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...   \n",
              "5   [(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...   \n",
              "6   [(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...   \n",
              "7   [(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...   \n",
              "8   [(15, 1), (20, 1), (44, 1), (59, 1), (61, 1), ...   \n",
              "9   [(15, 1), (63, 2), (71, 1), (77, 1), (93, 1), ...   \n",
              "10  [(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...   \n",
              "11  [(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...   \n",
              "12  [(43, 1), (63, 2), (71, 1), (93, 1), (103, 1),...   \n",
              "13  [(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...   \n",
              "14  [(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...   \n",
              "\n",
              "                                      opo_int_bow_lem  \n",
              "0   [(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (6, 2...  \n",
              "1   [(1, 1), (6, 2), (21, 1), (43, 2), (44, 2), (4...  \n",
              "2   [(15, 1), (21, 2), (55, 1), (61, 3), (63, 1), ...  \n",
              "3   [(44, 3), (48, 1), (54, 1), (55, 3), (56, 1), ...  \n",
              "4   [(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...  \n",
              "5   [(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...  \n",
              "6   [(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...  \n",
              "7   [(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...  \n",
              "8   [(15, 1), (20, 1), (44, 1), (55, 1), (59, 1), ...  \n",
              "9   [(15, 1), (55, 1), (63, 2), (71, 1), (77, 1), ...  \n",
              "10  [(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...  \n",
              "11  [(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...  \n",
              "12  [(43, 1), (63, 2), (71, 1), (93, 1), (97, 2), ...  \n",
              "13  [(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...  \n",
              "14  [(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_texto_tokens</th>\n",
              "      <th>opo_int_bow</th>\n",
              "      <th>opo_int_bow_lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[gender, 2021, caption, interviewing, communit...</td>\n",
              "      <td>[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (6, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[department, scientific, technological, policy...</td>\n",
              "      <td>[(1, 1), (6, 1), (21, 1), (43, 2), (44, 2), (4...</td>\n",
              "      <td>[(1, 1), (6, 2), (21, 1), (43, 2), (44, 2), (4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[vacancy, graduates, technical, course, studen...</td>\n",
              "      <td>[(15, 1), (21, 2), (61, 3), (63, 1), (70, 2), ...</td>\n",
              "      <td>[(15, 1), (21, 2), (55, 1), (61, 3), (63, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n",
              "      <td>[(44, 3), (48, 1), (54, 1), (55, 1), (56, 1), ...</td>\n",
              "      <td>[(44, 3), (48, 1), (54, 1), (55, 3), (56, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[registration, open, selection, one, 01, schol...</td>\n",
              "      <td>[(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...</td>\n",
              "      <td>[(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[technical, training, scholarship, level, iv, ...</td>\n",
              "      <td>[(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...</td>\n",
              "      <td>[(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[candidate, desired, skills, experience, molec...</td>\n",
              "      <td>[(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...</td>\n",
              "      <td>[(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[prerequisites, graduation, biology, zootechni...</td>\n",
              "      <td>[(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...</td>\n",
              "      <td>[(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[consultancy, specialized, application, develo...</td>\n",
              "      <td>[(15, 1), (20, 1), (44, 1), (59, 1), (61, 1), ...</td>\n",
              "      <td>[(15, 1), (20, 1), (44, 1), (55, 1), (59, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[collaborative, project, within, department, b...</td>\n",
              "      <td>[(15, 1), (63, 2), (71, 1), (77, 1), (93, 1), ...</td>\n",
              "      <td>[(15, 1), (55, 1), (63, 2), (71, 1), (77, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[multi, structural, crystallography, laborator...</td>\n",
              "      <td>[(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...</td>\n",
              "      <td>[(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[vacancy, postdoctoral, researcher, code, scho...</td>\n",
              "      <td>[(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...</td>\n",
              "      <td>[(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[opportunity, 1, level, three, technical, trai...</td>\n",
              "      <td>[(43, 1), (63, 2), (71, 1), (93, 1), (103, 1),...</td>\n",
              "      <td>[(43, 1), (63, 2), (71, 1), (93, 1), (97, 2), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[research, innovation, biodiversity, pharmaceu...</td>\n",
              "      <td>[(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...</td>\n",
              "      <td>[(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[research, innovation, biodiversity, pharmaceu...</td>\n",
              "      <td>[(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...</td>\n",
              "      <td>[(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eIfZjGyHUAv"
      },
      "source": [
        "### TF-IDF\n",
        "\n",
        "O TF-IDF (*term frequency - inverse document frequency*) é uma ferramenta estatística utilizada para ponderação de pesos de termos em documentos. Em suma, a ferramenta atribui pesos aos termos em uma coleção de documentos dados dois parâmetros: a quantidade de vezes que um termo aparece em um documento específico e quantas vezes aparece na coleção como um todo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StOIf88DHUAv"
      },
      "source": [
        "Term Frequency - Inverse Document Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeAnCNuHHUAv"
      },
      "source": [
        "from gensim.models.tfidfmodel import TfidfModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJa6HaCMHUAv"
      },
      "source": [
        "def tfdif_palavras_mais_representativas(col_tfidf, dicionario, top=5):\n",
        "    palavras_mais_repr = []\n",
        "    for idx, tfidf_doc in enumerate(col_tfidf):\n",
        "        palavras =[]\n",
        "        # lista ordenada pelo peso tfidf do termo\n",
        "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
        "\n",
        "        # lista no tamanho especificado\n",
        "        tfidf_desc_tam = tfidf_desc[:top]\n",
        "\n",
        "        # conversão dos tokenids para palavras\n",
        "        palavras = [(dicionario.get(tokenid), peso) for tokenid, peso in tfidf_desc_tam]\n",
        "        palavras_mais_repr.append({f'Palavra_Rank_{rank + 1}': palavras[rank] for rank in range(len(palavras))})\n",
        "\n",
        "    return pd.DataFrame(palavras_mais_repr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg8crpMyHUAw"
      },
      "source": [
        "def gera_tfidf_mais_representativos(serie_int_bow, tam=10):\n",
        "    \"\"\"Gera um dataframe com os dados de tfidf\n",
        "    para os `tam` tokens mais representativos de cada documento\"\"\"\n",
        "    \n",
        "    corpus = serie_int_bow.to_list()\n",
        "    tfidf = TfidfModel(corpus=corpus)\n",
        "    \n",
        "    tfidf_docs = []\n",
        "    for idx, doc in enumerate(corpus):\n",
        "        tfidf_doc = tfidf[doc]\n",
        "    \n",
        "        # lista ordenada pelo peso tfidf do termo\n",
        "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
        "\n",
        "        # lista no tamanho especificado\n",
        "        tfidf_desc_tam = tfidf_desc[:tam]\n",
        "\n",
        "        tfidf_docs.append({f'tdidf_desc_tam_{tam}': tfidf_desc_tam})\n",
        "        \n",
        "    return pd.DataFrame(tfidf_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WugbZnqHUAw"
      },
      "source": [
        "# Gera colunas com os tfidfs para cada documento\n",
        "X['opo_int_tfidf'] = gera_tfidf_mais_representativos(X['opo_int_bow'], tam=30)\n",
        "X['opo_int_tfidf_lem'] = gera_tfidf_mais_representativos(X['opo_int_bow_lem'], tam=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRVeThoeHUAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELFZ9kWJHUAw"
      },
      "source": [
        "Resultado do TF-IDF para o corpus normal e o lematizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yf-Qn06HUAw",
        "outputId": "bd1f4297-0ea8-49fd-841a-2d644ffe0eae"
      },
      "source": [
        "X[['opo_int_tfidf', 'opo_int_tfidf_lem']].head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       opo_int_tfidf  \\\n",
              "0  [(41, 0.36756587588835876), (33, 0.33520330695...   \n",
              "1  [(128, 0.34398110623892564), (92, 0.3060948373...   \n",
              "2  [(164, 0.45424157947496496), (198, 0.287162733...   \n",
              "3  [(259, 0.25464027448556886), (124, 0.191327449...   \n",
              "\n",
              "                                   opo_int_tfidf_lem  \n",
              "0  [(5064, 0.38837366192956346), (33, 0.311098952...  \n",
              "1  [(128, 0.3581655100099124), (92, 0.31421016951...  \n",
              "2  [(164, 0.4642261881533202), (198, 0.2934748096...  \n",
              "3  [(259, 0.26564610890151963), (226, 0.179891246...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opo_int_tfidf</th>\n",
              "      <th>opo_int_tfidf_lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(41, 0.36756587588835876), (33, 0.33520330695...</td>\n",
              "      <td>[(5064, 0.38837366192956346), (33, 0.311098952...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(128, 0.34398110623892564), (92, 0.3060948373...</td>\n",
              "      <td>[(128, 0.3581655100099124), (92, 0.31421016951...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(164, 0.45424157947496496), (198, 0.287162733...</td>\n",
              "      <td>[(164, 0.4642261881533202), (198, 0.2934748096...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(259, 0.25464027448556886), (124, 0.191327449...</td>\n",
              "      <td>[(259, 0.26564610890151963), (226, 0.179891246...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B71ayqmpHUAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHF8RBSoHUAx"
      },
      "source": [
        "Checando as palavras mais importantes por documento, segundo seu TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ApJ0MUPMHUAx",
        "outputId": "544a989d-29ca-426d-b31d-232bf6365964"
      },
      "source": [
        "tfdif_palavras_mais_representativas(X['opo_int_tfidf_lem'], dicionario_corpus, top=8).head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Palavra_Rank_1                        Palavra_Rank_2  \\\n",
              "0       (voice, 0.38837366192956346)         (product, 0.3110989527314427)   \n",
              "1         (spec, 0.3581655100099124)      (innovation, 0.3142101695125779)   \n",
              "2         (fish, 0.4642261881533202)  (slaughterhouse, 0.2934748096072516)   \n",
              "3  (philosophy, 0.26564610890151963)        (chapter, 0.17989124683007748)   \n",
              "4   (computing, 0.41388045847819366)          (30982, 0.19815141229263444)   \n",
              "5           (iv, 0.3744760568493732)            (back, 0.2907742650502568)   \n",
              "\n",
              "                       Palavra_Rank_3                      Palavra_Rank_4  \\\n",
              "0  (conservation, 0.2827228125679771)          (238, 0.22341486140644695)   \n",
              "1  (technological, 0.249367733120263)       (policy, 0.17954866829290167)   \n",
              "2        (trader, 0.2934748096072516)  (mathematical, 0.1659341820794618)   \n",
              "3   (specifying, 0.17989124683007748)      (studied, 0.17989124683007748)   \n",
              "4     (updating, 0.19815141229263444)   (scholarship, 0.1904302283248926)   \n",
              "5   (proficient, 0.21326815311297048)    (prototype, 0.21326815311297048)   \n",
              "\n",
              "                       Palavra_Rank_5                       Palavra_Rank_6  \\\n",
              "0      (caption, 0.22341486140644695)  (interviewing, 0.22341486140644695)   \n",
              "1           (202, 0.1790827550049562)            (378, 0.1790827550049562)   \n",
              "2     (industry, 0.15583535627011538)       (agrarian, 0.1467374048036258)   \n",
              "3        (table, 0.17989124683007748)    (translated, 0.17989124683007748)   \n",
              "4           (br, 0.17245963182909174)     (automation, 0.1722284478394696)   \n",
              "5  (refactoring, 0.21326815311297048)    (scheduling, 0.21326815311297048)   \n",
              "\n",
              "                       Palavra_Rank_7                  Palavra_Rank_8  \n",
              "0       (credit, 0.19418683096478173)   (engage, 0.19418683096478173)  \n",
              "1           (553, 0.1790827550049562)      (6230, 0.1790827550049562)  \n",
              "2  (codification, 0.1467374048036258)    (debate, 0.1467374048036258)  \n",
              "3    (variation, 0.17989124683007748)  (required, 0.1775346207759335)  \n",
              "4       (diploma, 0.1722284478394696)    (script, 0.1722284478394696)  \n",
              "5        (press, 0.18536755584659836)     (rest, 0.18536755584659836)  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Palavra_Rank_1</th>\n",
              "      <th>Palavra_Rank_2</th>\n",
              "      <th>Palavra_Rank_3</th>\n",
              "      <th>Palavra_Rank_4</th>\n",
              "      <th>Palavra_Rank_5</th>\n",
              "      <th>Palavra_Rank_6</th>\n",
              "      <th>Palavra_Rank_7</th>\n",
              "      <th>Palavra_Rank_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(voice, 0.38837366192956346)</td>\n",
              "      <td>(product, 0.3110989527314427)</td>\n",
              "      <td>(conservation, 0.2827228125679771)</td>\n",
              "      <td>(238, 0.22341486140644695)</td>\n",
              "      <td>(caption, 0.22341486140644695)</td>\n",
              "      <td>(interviewing, 0.22341486140644695)</td>\n",
              "      <td>(credit, 0.19418683096478173)</td>\n",
              "      <td>(engage, 0.19418683096478173)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(spec, 0.3581655100099124)</td>\n",
              "      <td>(innovation, 0.3142101695125779)</td>\n",
              "      <td>(technological, 0.249367733120263)</td>\n",
              "      <td>(policy, 0.17954866829290167)</td>\n",
              "      <td>(202, 0.1790827550049562)</td>\n",
              "      <td>(378, 0.1790827550049562)</td>\n",
              "      <td>(553, 0.1790827550049562)</td>\n",
              "      <td>(6230, 0.1790827550049562)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(fish, 0.4642261881533202)</td>\n",
              "      <td>(slaughterhouse, 0.2934748096072516)</td>\n",
              "      <td>(trader, 0.2934748096072516)</td>\n",
              "      <td>(mathematical, 0.1659341820794618)</td>\n",
              "      <td>(industry, 0.15583535627011538)</td>\n",
              "      <td>(agrarian, 0.1467374048036258)</td>\n",
              "      <td>(codification, 0.1467374048036258)</td>\n",
              "      <td>(debate, 0.1467374048036258)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(philosophy, 0.26564610890151963)</td>\n",
              "      <td>(chapter, 0.17989124683007748)</td>\n",
              "      <td>(specifying, 0.17989124683007748)</td>\n",
              "      <td>(studied, 0.17989124683007748)</td>\n",
              "      <td>(table, 0.17989124683007748)</td>\n",
              "      <td>(translated, 0.17989124683007748)</td>\n",
              "      <td>(variation, 0.17989124683007748)</td>\n",
              "      <td>(required, 0.1775346207759335)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(computing, 0.41388045847819366)</td>\n",
              "      <td>(30982, 0.19815141229263444)</td>\n",
              "      <td>(updating, 0.19815141229263444)</td>\n",
              "      <td>(scholarship, 0.1904302283248926)</td>\n",
              "      <td>(br, 0.17245963182909174)</td>\n",
              "      <td>(automation, 0.1722284478394696)</td>\n",
              "      <td>(diploma, 0.1722284478394696)</td>\n",
              "      <td>(script, 0.1722284478394696)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(iv, 0.3744760568493732)</td>\n",
              "      <td>(back, 0.2907742650502568)</td>\n",
              "      <td>(proficient, 0.21326815311297048)</td>\n",
              "      <td>(prototype, 0.21326815311297048)</td>\n",
              "      <td>(refactoring, 0.21326815311297048)</td>\n",
              "      <td>(scheduling, 0.21326815311297048)</td>\n",
              "      <td>(press, 0.18536755584659836)</td>\n",
              "      <td>(rest, 0.18536755584659836)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ61AH0hHUAx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qY1XHJPHUAx"
      },
      "source": [
        "### Conjuntos de Treinamento e de Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfG6S_LHUAx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuKkL7P8HUAy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLQix1L_HUAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuOVNBJpHUAy"
      },
      "source": [
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
        "\n",
        "# Transform the training data: tfidf_train \n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data: tfidf_test \n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Print the first 10 features\n",
        "print(tfidf_vectorizer.get_feature_names()[:50])\n",
        "\n",
        "# Print the first 5 vectors of the tfidf training data\n",
        "print(tfidf_train.A[:15])\n",
        "\n",
        "# Create the CountVectorizer DataFrame: count_df\n",
        "#count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
        "\n",
        "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
        "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaq49si0HUAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRviOzW9HUAz"
      },
      "source": [
        "### Métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFA5TE5THUAz"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic_0LzVPHUAz"
      },
      "source": [
        "def avalia_resultado(y_test, y_pred):\n",
        "    print(f' Acurácia:\\t{100 * accuracy_score(y_test, y_pred):.2f} %')\n",
        "    print(\" Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred, labels=['N', 'Y']))\n",
        "    print(\" Relatório de classificação:\\n\", classification_report(y_test, y_pred, labels=['N', 'Y']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYgzh-OHUAz"
      },
      "source": [
        "### Divisão dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTS8ThdkHUA0"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcckkOxJHUA0"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHdHwY3OHUA0"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.25)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X['opo_texto_sem_stop_lem'], y, stratify=y, test_size=0.25) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAPzvSAQHUA1"
      },
      "source": [
        "### Classificação com Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDhWdq98HUA1"
      },
      "source": [
        "#### Naive Bayes com Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prmcabVOHUA1"
      },
      "source": [
        "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "X_bow_train = count_vectorizer.fit_transform(X_train)\n",
        "X_bow_test = count_vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEKbsRVEHUA1"
      },
      "source": [
        "def classifica_NB_bow_alpha(alpha=1):\n",
        "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
        "    print(f'\\n{\"-\"*45}')\n",
        "    print(f'Naive Bayes - BoW')\n",
        "    print(f'{\"-\"*45}')\n",
        "    classificador_bow = MultinomialNB(alpha=alpha)\n",
        "    classificador_bow.fit(X_bow_train, y_train.values.ravel())\n",
        "    y_pred_bow = classificador_bow.predict(X_bow_test)\n",
        "    avalia_resultado(y_test, y_pred_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8Waa-LfIHUA1",
        "outputId": "830204b7-55b6-4e55-b739-63a2ef062661"
      },
      "source": [
        "# Varia o parâmetro alpha para checar qual o melhor\n",
        "alphas = np.arange(0.01, 1, 0.2)\n",
        "for alpha in alphas:\n",
        "    classifica_NB_bow_alpha(alpha=alpha)\n",
        "    # 0.01, 0.21, 0.41, 0.61, 0.81"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01 0.21 0.41 0.61 0.81]\n",
            "\n",
            "---------------------------------------------\n",
            "Naive Bayes - BoW\n",
            "---------------------------------------------\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[15  3]\n",
            " [ 6 26]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.83      0.77        18\n",
            "           Y       0.90      0.81      0.85        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.81      0.82      0.81        50\n",
            "weighted avg       0.83      0.82      0.82        50\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Naive Bayes - BoW\n",
            "---------------------------------------------\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[17  1]\n",
            " [10 22]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.63      0.94      0.76        18\n",
            "           Y       0.96      0.69      0.80        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.79      0.82      0.78        50\n",
            "weighted avg       0.84      0.78      0.78        50\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Naive Bayes - BoW\n",
            "---------------------------------------------\n",
            " Acurácia:\t76.00 %\n",
            " Matriz de Confusão:\n",
            " [[17  1]\n",
            " [11 21]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.61      0.94      0.74        18\n",
            "           Y       0.95      0.66      0.78        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.78      0.80      0.76        50\n",
            "weighted avg       0.83      0.76      0.76        50\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Naive Bayes - BoW\n",
            "---------------------------------------------\n",
            " Acurácia:\t76.00 %\n",
            " Matriz de Confusão:\n",
            " [[17  1]\n",
            " [11 21]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.61      0.94      0.74        18\n",
            "           Y       0.95      0.66      0.78        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.78      0.80      0.76        50\n",
            "weighted avg       0.83      0.76      0.76        50\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Naive Bayes - BoW\n",
            "---------------------------------------------\n",
            " Acurácia:\t76.00 %\n",
            " Matriz de Confusão:\n",
            " [[17  1]\n",
            " [11 21]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.61      0.94      0.74        18\n",
            "           Y       0.95      0.66      0.78        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.78      0.80      0.76        50\n",
            "weighted avg       0.83      0.76      0.76        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkeeVvBtHUA2"
      },
      "source": [
        "#### Naive Bayes com TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i0ohhKHHUA2"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQl2H_ETHUA2"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_tfidf_test = tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjP7n1QkHUA2"
      },
      "source": [
        "def classifica_NB_tfidf_alpha(alpha, verb=True):\n",
        "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
        "    print(f'\\n{\"-\"*55}')\n",
        "    print(f'Naive Bayes - TF-IDF')\n",
        "    print(f'{\"-\"*55}\\nAlpha = {alpha:.2f}:\\n{\"-\"*55}')\n",
        "    classificador_tfidf = MultinomialNB(alpha=alpha)\n",
        "    classificador_tfidf.fit(X_tfidf_train, y_train.values.ravel())\n",
        "    y_pred_tfidf = classificador_tfidf.predict(X_tfidf_test)\n",
        "    if verb:\n",
        "        avalia_resultado(y_test, y_pred_tfidf)\n",
        "    \n",
        "    return classificador_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9esCUXxHUA2",
        "outputId": "898e5563-03b8-44d6-d8f9-7f021ba0a7d6"
      },
      "source": [
        "# Varia o parâmetro alpha para checar qual o melhor\n",
        "alphas = np.arange(0.01, 1, 0.2)\n",
        "alphas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01, 0.21, 0.41, 0.61, 0.81])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "e0HPuLlOHUA3",
        "outputId": "6f786b2a-5c28-4d97-b9fa-0257e31ea607"
      },
      "source": [
        "for alpha in alphas:\n",
        "    classifica_NB_tfidf_alpha(alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.01:\n",
            "-------------------------------------------------------\n",
            " Acurácia:\t86.00 %\n",
            " Matriz de Confusão:\n",
            " [[15  3]\n",
            " [ 4 28]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.79      0.83      0.81        18\n",
            "           Y       0.90      0.88      0.89        32\n",
            "\n",
            "    accuracy                           0.86        50\n",
            "   macro avg       0.85      0.85      0.85        50\n",
            "weighted avg       0.86      0.86      0.86        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.21:\n",
            "-------------------------------------------------------\n",
            " Acurácia:\t76.00 %\n",
            " Matriz de Confusão:\n",
            " [[11  7]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.69      0.61      0.65        18\n",
            "           Y       0.79      0.84      0.82        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.74      0.73      0.73        50\n",
            "weighted avg       0.76      0.76      0.76        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.41:\n",
            "-------------------------------------------------------\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 9  9]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.50      0.67        18\n",
            "           Y       0.78      1.00      0.88        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.89      0.75      0.77        50\n",
            "weighted avg       0.86      0.82      0.80        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.61:\n",
            "-------------------------------------------------------\n",
            " Acurácia:\t80.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 8 10]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.44      0.62        18\n",
            "           Y       0.76      1.00      0.86        32\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.88      0.72      0.74        50\n",
            "weighted avg       0.85      0.80      0.78        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.81:\n",
            "-------------------------------------------------------\n",
            " Acurácia:\t76.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 6 12]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.33      0.50        18\n",
            "           Y       0.73      1.00      0.84        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.86      0.67      0.67        50\n",
            "weighted avg       0.83      0.76      0.72        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITp66qYyHUA3",
        "outputId": "22d90c91-9309-472a-9772-1002074a3ef0"
      },
      "source": [
        "# Extraindo as características do melhor modelo\n",
        "# alpha foi 0.01\n",
        "nb_classifier = classifica_NB_tfidf_alpha(alpha=0.01, verb=False)\n",
        "\n",
        "labels = nb_classifier.classes_\n",
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
        "\n",
        "print(f'{labels[0]}:\\n{feat_with_weights[:15]}')\n",
        "print(f'\\n{labels[1]}:\\n{feat_with_weights[-15:]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------------------------\n",
            "Naive Bayes - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Alpha = 0.01:\n",
            "-------------------------------------------------------\n",
            "N:\n",
            "[(-11.491381210629868, '09'), (-11.491381210629868, '127'), (-11.491381210629868, '129'), (-11.491381210629868, '17th'), (-11.491381210629868, '20211'), (-11.491381210629868, '202117'), (-11.491381210629868, '202122'), (-11.491381210629868, '20222021'), (-11.491381210629868, '2030'), (-11.491381210629868, '222'), (-11.491381210629868, '2329'), (-11.491381210629868, '238'), (-11.491381210629868, '250'), (-11.491381210629868, '354'), (-11.491381210629868, '371')]\n",
            "\n",
            "Y:\n",
            "[(-5.706052659827187, 'acceptance'), (-5.6530697358048325, 'grant'), (-5.615985102368938, 'letter'), (-5.5612565809041214, 'country'), (-5.557736143665154, 'science'), (-5.540016450905657, 'organisation'), (-5.531964545281696, 'year'), (-5.521393413465941, 'br'), (-5.484795388809013, 'project'), (-5.314406280219622, 'scholarship'), (-5.166337877281388, 'twas'), (-5.06910641238818, 'application'), (-5.0433389529830635, 'fellowship'), (-4.9880901734051095, 'cost'), (-4.767839060590731, 'research')]\n",
            "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6ExRAUBHUA3"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3enKHb4HUA3"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KON8UTtyHUA3"
      },
      "source": [
        "tipos_svn = ['linear', 'rbf', 'sigmoid']\n",
        "C = [0.1, 0.3, 0.6, 0.8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qr3yn5nHUA4"
      },
      "source": [
        "def avalia_svm(descricao, tipo, X_train, y_train, X_test, y_test, C):\n",
        "    print(f'\\n{\"-\"*55}\\nSVM - {descricao}\\n{\"-\"*55}')\n",
        "    print(f'Kernel = {tipo}, C = {C}\\n')\n",
        "    clf = SVC(kernel=tipo, C=C)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    avalia_resultado(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm176ZQBHUA4"
      },
      "source": [
        "#### SVM - Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "aGeycORiHUA7",
        "outputId": "11a3810c-cd09-470a-ce7c-293c9ac32835"
      },
      "source": [
        "for tipo in tipos_svn:\n",
        "    for c in C:\n",
        "        avalia_svm(\"Bag of Words\", tipo, X_bow_train, y_train.values.ravel(), X_bow_test, y_test, C=c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.1\n",
            "\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.67      0.69        18\n",
            "           Y       0.82      0.84      0.83        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.76      0.76      0.76        50\n",
            "weighted avg       0.78      0.78      0.78        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.3\n",
            "\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.67      0.69        18\n",
            "           Y       0.82      0.84      0.83        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.76      0.76      0.76        50\n",
            "weighted avg       0.78      0.78      0.78        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.6\n",
            "\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.67      0.69        18\n",
            "           Y       0.82      0.84      0.83        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.76      0.76      0.76        50\n",
            "weighted avg       0.78      0.78      0.78        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.8\n",
            "\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.67      0.69        18\n",
            "           Y       0.82      0.84      0.83        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.76      0.76      0.76        50\n",
            "weighted avg       0.78      0.78      0.78        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.1\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.3\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.6\n",
            "\n",
            " Acurácia:\t68.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 2 16]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.11      0.20        18\n",
            "           Y       0.67      1.00      0.80        32\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.83      0.56      0.50        50\n",
            "weighted avg       0.79      0.68      0.58        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.8\n",
            "\n",
            " Acurácia:\t70.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 5 13]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.71      0.28      0.40        18\n",
            "           Y       0.70      0.94      0.80        32\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.71      0.61      0.60        50\n",
            "weighted avg       0.70      0.70      0.66        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.1\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.3\n",
            "\n",
            " Acurácia:\t60.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.62      0.94      0.75        32\n",
            "\n",
            "    accuracy                           0.60        50\n",
            "   macro avg       0.31      0.47      0.38        50\n",
            "weighted avg       0.40      0.60      0.48        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.6\n",
            "\n",
            " Acurácia:\t60.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.62      0.94      0.75        32\n",
            "\n",
            "    accuracy                           0.60        50\n",
            "   macro avg       0.31      0.47      0.38        50\n",
            "weighted avg       0.40      0.60      0.48        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - Bag of Words\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.8\n",
            "\n",
            " Acurácia:\t60.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.62      0.94      0.75        32\n",
            "\n",
            "    accuracy                           0.60        50\n",
            "   macro avg       0.31      0.47      0.38        50\n",
            "weighted avg       0.40      0.60      0.48        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i7ncY6GHUA7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtjaJeglHUA8"
      },
      "source": [
        "#### SVM - TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Veg-8LBPHUA8",
        "outputId": "4420c0ff-7c44-4914-e53c-ae5d29b64881"
      },
      "source": [
        "for tipo in tipos_svn:\n",
        "    for c in C:\n",
        "        avalia_svm(\"TF-IDF\", tipo, X_tfidf_train, y_train.values.ravel(), X_tfidf_test,y_test, C=c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.1\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.3\n",
            "\n",
            " Acurácia:\t68.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 2 16]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.11      0.20        18\n",
            "           Y       0.67      1.00      0.80        32\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.83      0.56      0.50        50\n",
            "weighted avg       0.79      0.68      0.58        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.6\n",
            "\n",
            " Acurácia:\t72.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 6 12]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.75      0.33      0.46        18\n",
            "           Y       0.71      0.94      0.81        32\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.73      0.64      0.64        50\n",
            "weighted avg       0.73      0.72      0.69        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = linear, C = 0.8\n",
            "\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.80      0.67      0.73        18\n",
            "           Y       0.83      0.91      0.87        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.81      0.79      0.80        50\n",
            "weighted avg       0.82      0.82      0.82        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.1\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.3\n",
            "\n",
            " Acurácia:\t68.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 2 16]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.11      0.20        18\n",
            "           Y       0.67      1.00      0.80        32\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.83      0.56      0.50        50\n",
            "weighted avg       0.79      0.68      0.58        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.6\n",
            "\n",
            " Acurácia:\t72.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 5 13]\n",
            " [ 1 31]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.83      0.28      0.42        18\n",
            "           Y       0.70      0.97      0.82        32\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.77      0.62      0.62        50\n",
            "weighted avg       0.75      0.72      0.67        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = rbf, C = 0.8\n",
            "\n",
            " Acurácia:\t70.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 6 12]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.67      0.33      0.44        18\n",
            "           Y       0.71      0.91      0.79        32\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.69      0.62      0.62        50\n",
            "weighted avg       0.69      0.70      0.67        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.1\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.3\n",
            "\n",
            " Acurácia:\t64.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 0 18]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.00      0.00      0.00        18\n",
            "           Y       0.64      1.00      0.78        32\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.32      0.50      0.39        50\n",
            "weighted avg       0.41      0.64      0.50        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.6\n",
            "\n",
            " Acurácia:\t74.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 5 13]\n",
            " [ 0 32]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       1.00      0.28      0.43        18\n",
            "           Y       0.71      1.00      0.83        32\n",
            "\n",
            "    accuracy                           0.74        50\n",
            "   macro avg       0.86      0.64      0.63        50\n",
            "weighted avg       0.82      0.74      0.69        50\n",
            "\n",
            "\n",
            "-------------------------------------------------------\n",
            "SVM - TF-IDF\n",
            "-------------------------------------------------------\n",
            "Kernel = sigmoid, C = 0.8\n",
            "\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[10  8]\n",
            " [ 1 31]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.91      0.56      0.69        18\n",
            "           Y       0.79      0.97      0.87        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.85      0.76      0.78        50\n",
            "weighted avg       0.84      0.82      0.81        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIGQsF3bHUA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHZn-1WdHUA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPBM2lksHUA8"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiodYFuWHUA9"
      },
      "source": [
        "from numpy.core.umath_tests import inner1d\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfD6iOkRHUA9"
      },
      "source": [
        "n_estimadores = [5, 10, 100, 500, 1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krHOMVHlHUA9"
      },
      "source": [
        "def avalia_random_forest(descricao, X_train, y_train, X_test, n_est):\n",
        "    print(f'\\n{\"-\"*60}\\nRandom Forest - {descricao}\\n{\"-\"*60}')\n",
        "    print(f'No estimadores = {n_est}\\n')\n",
        "    classifier = RandomForestClassifier(n_estimators=n_est)\n",
        "    classifier.fit(X_train, y_train) \n",
        "    y_pred = classifier.predict(X_test)\n",
        "    avalia_resultado(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8K4GQjOHUA9"
      },
      "source": [
        "#### Random Forest - Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNUpmW-uHUA-",
        "outputId": "55029e31-a19c-4f5a-d2fd-bbd22660c38b"
      },
      "source": [
        "for n_est in n_estimadores:\n",
        "    avalia_random_forest('BoW', X_bow_train, y_train.values.ravel(), X_bow_test, n_est=n_est)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 5\n",
            "\n",
            " Acurácia:\t68.00 %\n",
            " Matriz de Confusão:\n",
            " [[ 6 12]\n",
            " [ 4 28]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.60      0.33      0.43        18\n",
            "           Y       0.70      0.88      0.78        32\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.65      0.60      0.60        50\n",
            "weighted avg       0.66      0.68      0.65        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 10\n",
            "\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[14  4]\n",
            " [ 5 27]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.74      0.78      0.76        18\n",
            "           Y       0.87      0.84      0.86        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.80      0.81      0.81        50\n",
            "weighted avg       0.82      0.82      0.82        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 100\n",
            "\n",
            " Acurácia:\t80.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 4 28]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.75      0.67      0.71        18\n",
            "           Y       0.82      0.88      0.85        32\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.79      0.77      0.78        50\n",
            "weighted avg       0.80      0.80      0.80        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 500\n",
            "\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.80      0.67      0.73        18\n",
            "           Y       0.83      0.91      0.87        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.81      0.79      0.80        50\n",
            "weighted avg       0.82      0.82      0.82        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 1000\n",
            "\n",
            " Acurácia:\t80.00 %\n",
            " Matriz de Confusão:\n",
            " [[11  7]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.79      0.61      0.69        18\n",
            "           Y       0.81      0.91      0.85        32\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.80      0.76      0.77        50\n",
            "weighted avg       0.80      0.80      0.79        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp8vG_ThHUA-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP8Ge0NAHUA-"
      },
      "source": [
        "#### Random Forest -TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc9N2dxIHUA-",
        "outputId": "6376c8f8-e52b-486b-e73d-8b3e9c0d7b0e"
      },
      "source": [
        "for n_est in n_estimadores:\n",
        "    avalia_random_forest('BoW', X_tfidf_train, y_train.values.ravel(), X_tfidf_test, n_est=n_est)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 5\n",
            "\n",
            " Acurácia:\t72.00 %\n",
            " Matriz de Confusão:\n",
            " [[11  7]\n",
            " [ 7 25]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.61      0.61      0.61        18\n",
            "           Y       0.78      0.78      0.78        32\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.70      0.70      0.70        50\n",
            "weighted avg       0.72      0.72      0.72        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 10\n",
            "\n",
            " Acurácia:\t82.00 %\n",
            " Matriz de Confusão:\n",
            " [[13  5]\n",
            " [ 4 28]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.76      0.72      0.74        18\n",
            "           Y       0.85      0.88      0.86        32\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.81      0.80      0.80        50\n",
            "weighted avg       0.82      0.82      0.82        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 100\n",
            "\n",
            " Acurácia:\t84.00 %\n",
            " Matriz de Confusão:\n",
            " [[12  6]\n",
            " [ 2 30]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.86      0.67      0.75        18\n",
            "           Y       0.83      0.94      0.88        32\n",
            "\n",
            "    accuracy                           0.84        50\n",
            "   macro avg       0.85      0.80      0.82        50\n",
            "weighted avg       0.84      0.84      0.83        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 500\n",
            "\n",
            " Acurácia:\t78.00 %\n",
            " Matriz de Confusão:\n",
            " [[10  8]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.77      0.56      0.65        18\n",
            "           Y       0.78      0.91      0.84        32\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.78      0.73      0.74        50\n",
            "weighted avg       0.78      0.78      0.77        50\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "Random Forest - BoW\n",
            "------------------------------------------------------------\n",
            "No estimadores = 1000\n",
            "\n",
            " Acurácia:\t80.00 %\n",
            " Matriz de Confusão:\n",
            " [[11  7]\n",
            " [ 3 29]]\n",
            " Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           N       0.79      0.61      0.69        18\n",
            "           Y       0.81      0.91      0.85        32\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.80      0.76      0.77        50\n",
            "weighted avg       0.80      0.80      0.79        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcHClPg1HUA_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11SkT8M3HUA_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGb-BunDHUA_"
      },
      "source": [
        "### Cross-Validation BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PfGxLYvHUA_",
        "outputId": "865c6af2-f859-4749-f5f2-1afe2467d75e"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "models = [MultinomialNB(alpha=0.01), # 0.01, 0.21, 0.41, 0.61, 0.81\n",
        "MultinomialNB(alpha=0.21),MultinomialNB(alpha=0.41),MultinomialNB(alpha=0.61),MultinomialNB(alpha=0.81),\n",
        "# tipos_svn = ['linear', 'rbf', 'sigmoid'] C = [0.1, 0.3, 0.6, 0.8]\n",
        " SVC(kernel = 'linear', C = 0.1),SVC(kernel = 'linear', C = 0.3), SVC(kernel = 'linear', C = 0.6),SVC(kernel = 'linear', C = 0.8),\n",
        " SVC(kernel = 'rbf', C = 0.1),SVC(kernel = 'rbf', C = 0.3), SVC(kernel = 'rbf', C = 0.6),SVC(kernel = 'rbf', C = 0.8),\n",
        " SVC(kernel = 'sigmoid', C = 0.1),SVC(kernel = 'sigmoid', C = 0.3), SVC(kernel = 'sigmoid', C = 0.6),SVC(kernel = 'sigmoid', C = 0.8),\n",
        " #[5, 10, 100, 500, 1000]\n",
        "RandomForestClassifier(5),RandomForestClassifier(10),RandomForestClassifier(100),RandomForestClassifier(500),RandomForestClassifier(1000)]\n",
        "# score de cada modelo\n",
        "models_scores = []\n",
        "for model in models:\n",
        "    val_scores = cross_val_score(model, X_bow_train, y_train.values.ravel(), cv=50)\n",
        "    #nome_modelo = type(model).__name__ # somente para exibição\n",
        "    print(model)\n",
        "    #parametro_modelo=type(model).__kargs__\n",
        "    print('Média: {:.2} | Desvio: {:.2}'.format( np.mean(val_scores), np.std(val_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB(alpha=0.01)\n",
            "Média: 0.79 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.21)\n",
            "Média: 0.76 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.41)\n",
            "Média: 0.75 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.61)\n",
            "Média: 0.75 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.81)\n",
            "Média: 0.75 | Desvio: 0.24\n",
            "SVC(C=0.1, kernel='linear')\n",
            "Média: 0.78 | Desvio: 0.23\n",
            "SVC(C=0.3, kernel='linear')\n",
            "Média: 0.77 | Desvio: 0.23\n",
            "SVC(C=0.6, kernel='linear')\n",
            "Média: 0.77 | Desvio: 0.23\n",
            "SVC(C=0.8, kernel='linear')\n",
            "Média: 0.77 | Desvio: 0.23\n",
            "SVC(C=0.1)\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.3)\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.6)\n",
            "Média: 0.65 | Desvio: 0.079\n",
            "SVC(C=0.8)\n",
            "Média: 0.68 | Desvio: 0.15\n",
            "SVC(C=0.1, kernel='sigmoid')\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.3, kernel='sigmoid')\n",
            "Média: 0.61 | Desvio: 0.14\n",
            "SVC(C=0.6, kernel='sigmoid')\n",
            "Média: 0.6 | Desvio: 0.15\n",
            "SVC(C=0.8, kernel='sigmoid')\n",
            "Média: 0.59 | Desvio: 0.14\n",
            "RandomForestClassifier(n_estimators=5)\n",
            "Média: 0.78 | Desvio: 0.2\n",
            "RandomForestClassifier(n_estimators=10)\n",
            "Média: 0.79 | Desvio: 0.22\n",
            "RandomForestClassifier()\n",
            "Média: 0.81 | Desvio: 0.22\n",
            "RandomForestClassifier(n_estimators=500)\n",
            "Média: 0.79 | Desvio: 0.22\n",
            "RandomForestClassifier(n_estimators=1000)\n",
            "Média: 0.79 | Desvio: 0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ik96f5YHUBA"
      },
      "source": [
        "### Cross-Validation TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXa2WEz-HUBA"
      },
      "source": [
        "\n",
        "# Cross-Validation TFIDF\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPcjiADxHUBA",
        "outputId": "e0aeb77f-147b-4380-b3a9-4d47b5fc47fe"
      },
      "source": [
        "models = [MultinomialNB(alpha=0.01), # 0.01, 0.21, 0.41, 0.61, 0.81\n",
        "MultinomialNB(alpha=0.21),MultinomialNB(alpha=0.41),MultinomialNB(alpha=0.61),MultinomialNB(alpha=0.81),\n",
        "# tipos_svn = ['linear', 'rbf', 'sigmoid'] C = [0.1, 0.3, 0.6, 0.8]\n",
        " SVC(kernel = 'linear', C = 0.1),SVC(kernel = 'linear', C = 0.3), SVC(kernel = 'linear', C = 0.6),SVC(kernel = 'linear', C = 0.8),\n",
        " SVC(kernel = 'rbf', C = 0.1),SVC(kernel = 'rbf', C = 0.3), SVC(kernel = 'rbf', C = 0.6),SVC(kernel = 'rbf', C = 0.8),\n",
        " SVC(kernel = 'sigmoid', C = 0.1),SVC(kernel = 'sigmoid', C = 0.3), SVC(kernel = 'sigmoid', C = 0.6),SVC(kernel = 'sigmoid', C = 0.8),\n",
        " #[5, 10, 100, 500, 1000]\n",
        "RandomForestClassifier(5),RandomForestClassifier(10),RandomForestClassifier(100),RandomForestClassifier(500),RandomForestClassifier(1000)]\n",
        "# score de cada modelo\n",
        "models_scores = []\n",
        "for model in models:\n",
        "    val_scores = cross_val_score(model, X_tfidf_train, y_train.values.ravel(), cv=50)\n",
        "    print(model)\n",
        "    #parametro_modelo=type(model).__kargs__\n",
        "    print('Média: {:.2} | Desvio: {:.2}'.format( np.mean(val_scores), np.std(val_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB(alpha=0.01)\n",
            "Média: 0.75 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.21)\n",
            "Média: 0.75 | Desvio: 0.25\n",
            "MultinomialNB(alpha=0.41)\n",
            "Média: 0.77 | Desvio: 0.24\n",
            "MultinomialNB(alpha=0.61)\n",
            "Média: 0.71 | Desvio: 0.21\n",
            "MultinomialNB(alpha=0.81)\n",
            "Média: 0.7 | Desvio: 0.19\n",
            "SVC(C=0.1, kernel='linear')\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.3, kernel='linear')\n",
            "Média: 0.68 | Desvio: 0.11\n",
            "SVC(C=0.6, kernel='linear')\n",
            "Média: 0.71 | Desvio: 0.23\n",
            "SVC(C=0.8, kernel='linear')\n",
            "Média: 0.77 | Desvio: 0.23\n",
            "SVC(C=0.1)\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.3)\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.6)\n",
            "Média: 0.68 | Desvio: 0.15\n",
            "SVC(C=0.8)\n",
            "Média: 0.73 | Desvio: 0.2\n",
            "SVC(C=0.1, kernel='sigmoid')\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.3, kernel='sigmoid')\n",
            "Média: 0.65 | Desvio: 0.065\n",
            "SVC(C=0.6, kernel='sigmoid')\n",
            "Média: 0.67 | Desvio: 0.24\n",
            "SVC(C=0.8, kernel='sigmoid')\n",
            "Média: 0.74 | Desvio: 0.23\n",
            "RandomForestClassifier(n_estimators=5)\n",
            "Média: 0.78 | Desvio: 0.2\n",
            "RandomForestClassifier(n_estimators=10)\n",
            "Média: 0.77 | Desvio: 0.23\n",
            "RandomForestClassifier()\n",
            "Média: 0.77 | Desvio: 0.22\n",
            "RandomForestClassifier(n_estimators=500)\n",
            "Média: 0.77 | Desvio: 0.2\n",
            "RandomForestClassifier(n_estimators=1000)\n",
            "Média: 0.77 | Desvio: 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}