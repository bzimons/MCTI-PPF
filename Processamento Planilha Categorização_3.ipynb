{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos de classificação com a planilha de oportunidades em texto\n",
    "\n",
    "https://github.com/mcti-sefip/mcti-sefip-ppfcd2020/blob/jairoalves-task_18/Processamento%20Planilha%20Categoriza%C3%A7%C3%A3o.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq = r\"C:\\Users\\bolin\\Desktop\\codigos\\mcti-sefip-ppfcd2020\\oportunidades_classificacao_3.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          opo_titulo  \\\n",
       "0     Knowledge Product to Strengthen Women's Voices   \n",
       "1  Bolsas de PD em Política Científica e Tecnológica   \n",
       "2                 Bolsa de TT-II em Ciência de Dados   \n",
       "3       Bolsa de PD em História da Filosofia Moderna   \n",
       "\n",
       "                                                link opo_brazil  \\\n",
       "0  https://www.cepf.net/grants/open-calls-for-pro...          N   \n",
       "1  http://fapesp.br/oportunidades/Control/../inov...          Y   \n",
       "2  http://fapesp.br/oportunidades/Control/../fish...          Y   \n",
       "3  http://fapesp.br/oportunidades/Control/../pode...          Y   \n",
       "\n",
       "    opo_deadline               codigo  \\\n",
       "0  30 April 2021   cepf_210429_01_000   \n",
       "1     30/04/2021  fapesp_210429_1_000   \n",
       "2     30/04/2021  fapesp_210429_1_001   \n",
       "3     30/04/2021  fapesp_210429_1_002   \n",
       "\n",
       "                                           opo_texto  \\\n",
       "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
       "1  Unicamp's Department of Scientific and Technol...   \n",
       "2  The vacancy is for graduates of a Technical Co...   \n",
       "3  The scholarship lasts for two years and can be...   \n",
       "\n",
       "                                       opo_texto_ele     opo_tipo  \\\n",
       "0   gender-cfp-2021.jpg Caption: Interviewing a c...        other   \n",
       "1  Unicamp's Department of Scientific and Technol...  scholarship   \n",
       "2  The vacancy is for graduates of a Technical Co...  scholarship   \n",
       "3  The scholarship lasts for two years and can be...  scholarship   \n",
       "\n",
       "   atualizacao clas comentario  \n",
       "0       210429    N        NaN  \n",
       "1       210429    Y        NaN  \n",
       "2       210429    Y        NaN  \n",
       "3       210429    Y        NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_titulo</th>\n      <th>link</th>\n      <th>opo_brazil</th>\n      <th>opo_deadline</th>\n      <th>codigo</th>\n      <th>opo_texto</th>\n      <th>opo_texto_ele</th>\n      <th>opo_tipo</th>\n      <th>atualizacao</th>\n      <th>clas</th>\n      <th>comentario</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Knowledge Product to Strengthen Women's Voices</td>\n      <td>https://www.cepf.net/grants/open-calls-for-pro...</td>\n      <td>N</td>\n      <td>30 April 2021</td>\n      <td>cepf_210429_01_000</td>\n      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n      <td>other</td>\n      <td>210429</td>\n      <td>N</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bolsas de PD em Política Científica e Tecnológica</td>\n      <td>http://fapesp.br/oportunidades/Control/../inov...</td>\n      <td>Y</td>\n      <td>30/04/2021</td>\n      <td>fapesp_210429_1_000</td>\n      <td>Unicamp's Department of Scientific and Technol...</td>\n      <td>Unicamp's Department of Scientific and Technol...</td>\n      <td>scholarship</td>\n      <td>210429</td>\n      <td>Y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bolsa de TT-II em Ciência de Dados</td>\n      <td>http://fapesp.br/oportunidades/Control/../fish...</td>\n      <td>Y</td>\n      <td>30/04/2021</td>\n      <td>fapesp_210429_1_001</td>\n      <td>The vacancy is for graduates of a Technical Co...</td>\n      <td>The vacancy is for graduates of a Technical Co...</td>\n      <td>scholarship</td>\n      <td>210429</td>\n      <td>Y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bolsa de PD em História da Filosofia Moderna</td>\n      <td>http://fapesp.br/oportunidades/Control/../pode...</td>\n      <td>Y</td>\n      <td>30/04/2021</td>\n      <td>fapesp_210429_1_002</td>\n      <td>The scholarship lasts for two years and can be...</td>\n      <td>The scholarship lasts for two years and can be...</td>\n      <td>scholarship</td>\n      <td>210429</td>\n      <td>Y</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Coleta das variáveis de interesse\n",
    "X = df[['opo_texto']].copy()\n",
    "y = df[['clas']].copy()\n",
    "# y = [re.sub(\" \",\"\",i) for i in str(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentenca():\n",
    "\n",
    "    def __init__(self, sentenca):\n",
    "        self.sent_bruta = sentenca\n",
    "        self.preproc()\n",
    "    \n",
    "    def remove_caracteres_nao_alfanumericos(self):\n",
    "        # padroes para trechos nao alfanumericos\n",
    "        ptn_nao_alfanum = r\"[\\W+]\"\n",
    "        self.sent_preproc = re.sub(ptn_nao_alfanum, ' ', self.sent_bruta)\n",
    "\n",
    "    def remove_a_chapeu(self):\n",
    "        # padroes para trechos nao alfanumericos\n",
    "        ptn_nao_chap = r\"(Â|â|œ)\"\n",
    "        self.sent_preproc = re.sub(ptn_nao_chap, ' ', self.sent_preproc)\n",
    "    \n",
    "    def remove_espacos_multiplos(self):\n",
    "        ptn_espacos_mult = r\"\\s+\"  \n",
    "        self.sent_preproc = re.sub(ptn_espacos_mult, ' ', self.sent_preproc)\n",
    "        self.sent_preproc = self.sent_preproc.strip()\n",
    "    \n",
    "    def remove_b_inicial(self):\n",
    "        if self.sent_preproc.startswith('b '):\n",
    "            self.sent_preproc = self.sent_preproc[2:]\n",
    "    \n",
    "    def separa_palavras_coladas(self):\n",
    "        \"\"\"Separa com espaço palavras coladas, aqui definido quando uma letra \n",
    "        minúscula está colada com uma maiúscula imediatalmente posterior\"\"\"\n",
    "        ptn_ltr_minusc_colada_maiuscula = r'([a-z])([A-Z])'\n",
    "        ptn_algarismo_colado_maiuscula = r'([0-9])([A-Z])'\n",
    "        \n",
    "        self.sent_preproc = re.sub(ptn_ltr_minusc_colada_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
    "        self.sent_preproc = re.sub(ptn_algarismo_colado_maiuscula, r'\\1 \\2', self.sent_preproc)\n",
    "    \n",
    "    def preproc(self):\n",
    "        self.sent_preproc = ''\n",
    "        self.remove_caracteres_nao_alfanumericos()\n",
    "        self.remove_a_chapeu()\n",
    "        self.remove_espacos_multiplos()\n",
    "        self.remove_b_inicial()\n",
    "        self.separa_palavras_coladas()\n",
    "        self.sent_preproc = self.sent_preproc.lower()\n",
    "        \n",
    "        return self.sent_preproc\n",
    "    \n",
    "    def __getitem__(self, indices):\n",
    "        return ''.join(self.sent_preproc[indices])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.sent_preproc)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.sent_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_preproc'] = X['opo_texto'].apply(Sentenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'gender cfp 2021 jpg caption interviewing a community member in lao pdr credit fishbio call for proposals development of an innovative knowledge product pertaining to the strengthening of women s voices in conservation opening date 22 march 2021 closing date 30 april 2021 questions due date 15 april 2021 s'"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "X['opo_texto_preproc'].iloc[0][:306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           opo_texto  \\\n",
       "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
       "1  Unicamp's Department of Scientific and Technol...   \n",
       "2  The vacancy is for graduates of a Technical Co...   \n",
       "3  The scholarship lasts for two years and can be...   \n",
       "\n",
       "                                   opo_texto_preproc  \n",
       "0  gender cfp 2021 jpg caption interviewing a com...  \n",
       "1  unicamp s department of scientific and technol...  \n",
       "2  the vacancy is for graduates of a technical co...  \n",
       "3  the scholarship lasts for two years and can be...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto</th>\n      <th>opo_texto_preproc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unicamp's Department of Scientific and Technol...</td>\n      <td>unicamp s department of scientific and technol...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The vacancy is for graduates of a Technical Co...</td>\n      <td>the vacancy is for graduates of a technical co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The scholarship lasts for two years and can be...</td>\n      <td>the scholarship lasts for two years and can be...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "X.head(4)"
   ]
  },
  {
   "source": [
    "### Stopwords"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 108,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           opo_texto  \\\n",
       "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
       "1  Unicamp's Department of Scientific and Technol...   \n",
       "2  The vacancy is for graduates of a Technical Co...   \n",
       "3  The scholarship lasts for two years and can be...   \n",
       "\n",
       "                                   opo_texto_preproc  \\\n",
       "0  gender cfp 2021 jpg caption interviewing a com...   \n",
       "1  unicamp s department of scientific and technol...   \n",
       "2  the vacancy is for graduates of a technical co...   \n",
       "3  the scholarship lasts for two years and can be...   \n",
       "\n",
       "                                     opo_texto_dicio  \n",
       "0  gender 2021 caption interviewing a community m...  \n",
       "1  s department of scientific and technological p...  \n",
       "2  the vacancy is for graduates of a technical co...  \n",
       "3  the scholarship lasts for two years and can be...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto</th>\n      <th>opo_texto_preproc</th>\n      <th>opo_texto_dicio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n      <td>gender 2021 caption interviewing a community m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unicamp's Department of Scientific and Technol...</td>\n      <td>unicamp s department of scientific and technol...</td>\n      <td>s department of scientific and technological p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The vacancy is for graduates of a Technical Co...</td>\n      <td>the vacancy is for graduates of a technical co...</td>\n      <td>the vacancy is for graduates of a technical co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The scholarship lasts for two years and can be...</td>\n      <td>the scholarship lasts for two years and can be...</td>\n      <td>the scholarship lasts for two years and can be...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "lista_texto = X['opo_texto_preproc'].tolist()\n",
    "lista_texto = [str(i) for i in lista_texto]\n",
    "# print(type((lista_texto[0])))\n",
    "values = ','.join(str(v) for v in lista_texto)\n",
    "unique_words = set(values.split(' '))\n",
    "unique_words = sorted(unique_words)\n",
    "\n",
    "import enchant # pip install pyenchant\n",
    "def frase_dicionario(frase):\n",
    "    d = enchant.Dict(\"en_GB\")\n",
    "    jus = frase.split(' ')\n",
    "    lista_frase_dic = [i for i in jus if d.check(i)]\n",
    "    frase_final = ' '.join(lista_frase_dic)\n",
    "    return(frase_final)\n",
    "\n",
    "opo_texto_dicio=[]\n",
    "for i in lista_texto: # não funcionou com listcompreension\n",
    "    opo_texto_dicio.append(frase_dicionario(i))\n",
    "\n",
    "X['opo_texto_dicio'] = opo_texto_dicio\n",
    "X.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ingles = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentenca):\n",
    "    tokens = str(sentenca).split(' ')\n",
    "    tokens_sem_stops = [token for token in tokens if token not in stop_ingles]\n",
    "    return ' '.join(tokens_sem_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troquei aqui para o dicio \n",
    "X['opo_texto_sem_stop'] = X['opo_texto_dicio'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           opo_texto  \\\n",
       "0   gender-cfp-2021.jpg Caption: Interviewing a c...   \n",
       "1  Unicamp's Department of Scientific and Technol...   \n",
       "2  The vacancy is for graduates of a Technical Co...   \n",
       "3  The scholarship lasts for two years and can be...   \n",
       "\n",
       "                                   opo_texto_preproc  \\\n",
       "0  gender cfp 2021 jpg caption interviewing a com...   \n",
       "1  unicamp s department of scientific and technol...   \n",
       "2  the vacancy is for graduates of a technical co...   \n",
       "3  the scholarship lasts for two years and can be...   \n",
       "\n",
       "                                     opo_texto_dicio  \\\n",
       "0  gender 2021 caption interviewing a community m...   \n",
       "1  s department of scientific and technological p...   \n",
       "2  the vacancy is for graduates of a technical co...   \n",
       "3  the scholarship lasts for two years and can be...   \n",
       "\n",
       "                                  opo_texto_sem_stop  \n",
       "0  gender 2021 caption interviewing community mem...  \n",
       "1  department scientific technological policy por...  \n",
       "2  vacancy graduates technical course student las...  \n",
       "3  scholarship lasts two years renewed another ye...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto</th>\n      <th>opo_texto_preproc</th>\n      <th>opo_texto_dicio</th>\n      <th>opo_texto_sem_stop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gender-cfp-2021.jpg Caption: Interviewing a c...</td>\n      <td>gender cfp 2021 jpg caption interviewing a com...</td>\n      <td>gender 2021 caption interviewing a community m...</td>\n      <td>gender 2021 caption interviewing community mem...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unicamp's Department of Scientific and Technol...</td>\n      <td>unicamp s department of scientific and technol...</td>\n      <td>s department of scientific and technological p...</td>\n      <td>department scientific technological policy por...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The vacancy is for graduates of a Technical Co...</td>\n      <td>the vacancy is for graduates of a technical co...</td>\n      <td>the vacancy is for graduates of a technical co...</td>\n      <td>vacancy graduates technical course student las...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The scholarship lasts for two years and can be...</td>\n      <td>the scholarship lasts for two years and can be...</td>\n      <td>the scholarship lasts for two years and can be...</td>\n      <td>scholarship lasts two years renewed another ye...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "X.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gender 2021 caption interviewing community member credit call proposals development innovative knowledge product pertaining strengthening women voices conservation opening date 22 march 2021 closing date 30 2021 questions due date 15 2021 submissions applications sent net closing date overview intends \n...\n"
     ]
    }
   ],
   "source": [
    "print(X['opo_texto_sem_stop'][0][:302], '\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_tokens'] = X['opo_texto_sem_stop'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['gender', '2021', 'caption', 'interviewing', 'community', 'member', 'credit', 'call', 'proposals', 'development', 'innovative', 'knowledge', 'product', 'pertaining', 'strengthening', 'women', 'voices', 'conservation', 'opening', 'date', '22', 'march', '2021', 'closing', 'date', '30', '2021', 'questions', 'due', 'date', '15', '2021', 'submissions', 'applications', 'sent', 'net', 'closing', 'date', 'overview', 'intends', 'engage', 'consultant', 'develop', 'knowledge', 'product', 'provide', 'guidance', 'strengthen', 'women', 'voices'] \n...\n"
     ]
    }
   ],
   "source": [
    "print(X['opo_texto_tokens'].iloc[0][:50], '\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematiza_tokens(tokens):\n",
    "    return [wordnet.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lematização dos tokens\n",
    "X['opo_texto_tokens_lem'] = X['opo_texto_tokens'].apply(lematiza_tokens)\n",
    "X['opo_texto_sem_stop_lem'] = X['opo_texto_tokens_lem'].apply(lambda l: ' '.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenização e Lematização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    opo_texto_tokens  \\\n",
       "0  [gender, 2021, caption, interviewing, communit...   \n",
       "1  [department, scientific, technological, policy...   \n",
       "2  [vacancy, graduates, technical, course, studen...   \n",
       "3  [scholarship, lasts, two, years, renewed, anot...   \n",
       "4  [registration, open, selection, one, 01, schol...   \n",
       "5  [technical, training, scholarship, level, iv, ...   \n",
       "6  [candidate, desired, skills, experience, molec...   \n",
       "7  [prerequisites, graduation, biology, zootechni...   \n",
       "8  [consultancy, specialized, application, develo...   \n",
       "9  [collaborative, project, within, department, b...   \n",
       "\n",
       "                                opo_texto_tokens_lem  \\\n",
       "0  [gender, 2021, caption, interviewing, communit...   \n",
       "1  [department, scientific, technological, policy...   \n",
       "2  [vacancy, graduate, technical, course, student...   \n",
       "3  [scholarship, last, two, year, renewed, anothe...   \n",
       "4  [registration, open, selection, one, 01, schol...   \n",
       "5  [technical, training, scholarship, level, iv, ...   \n",
       "6  [candidate, desired, skill, experience, molecu...   \n",
       "7  [prerequisite, graduation, biology, zootechnic...   \n",
       "8  [consultancy, specialized, application, develo...   \n",
       "9  [collaborative, project, within, department, b...   \n",
       "\n",
       "                              opo_texto_sem_stop_lem  \n",
       "0  gender 2021 caption interviewing community mem...  \n",
       "1  department scientific technological policy por...  \n",
       "2  vacancy graduate technical course student last...  \n",
       "3  scholarship last two year renewed another year...  \n",
       "4  registration open selection one 01 scholarship...  \n",
       "5  technical training scholarship level iv iv ava...  \n",
       "6  candidate desired skill experience molecular b...  \n",
       "7  prerequisite graduation biology zootechnics fi...  \n",
       "8  consultancy specialized application developmen...  \n",
       "9  collaborative project within department bioche...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto_tokens</th>\n      <th>opo_texto_tokens_lem</th>\n      <th>opo_texto_sem_stop_lem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[gender, 2021, caption, interviewing, communit...</td>\n      <td>[gender, 2021, caption, interviewing, communit...</td>\n      <td>gender 2021 caption interviewing community mem...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[department, scientific, technological, policy...</td>\n      <td>[department, scientific, technological, policy...</td>\n      <td>department scientific technological policy por...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[vacancy, graduates, technical, course, studen...</td>\n      <td>[vacancy, graduate, technical, course, student...</td>\n      <td>vacancy graduate technical course student last...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n      <td>[scholarship, last, two, year, renewed, anothe...</td>\n      <td>scholarship last two year renewed another year...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[registration, open, selection, one, 01, schol...</td>\n      <td>[registration, open, selection, one, 01, schol...</td>\n      <td>registration open selection one 01 scholarship...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[technical, training, scholarship, level, iv, ...</td>\n      <td>[technical, training, scholarship, level, iv, ...</td>\n      <td>technical training scholarship level iv iv ava...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[candidate, desired, skills, experience, molec...</td>\n      <td>[candidate, desired, skill, experience, molecu...</td>\n      <td>candidate desired skill experience molecular b...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[prerequisites, graduation, biology, zootechni...</td>\n      <td>[prerequisite, graduation, biology, zootechnic...</td>\n      <td>prerequisite graduation biology zootechnics fi...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[consultancy, specialized, application, develo...</td>\n      <td>[consultancy, specialized, application, develo...</td>\n      <td>consultancy specialized application developmen...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[collaborative, project, within, department, b...</td>\n      <td>[collaborative, project, within, department, b...</td>\n      <td>collaborative project within department bioche...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_texto_tokens_lem', 'opo_texto_sem_stop_lem']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['opo_texto_bow'] = X['opo_texto_tokens'].apply(Counter)\n",
    "X['opo_texto_bow_lem'] = X['opo_texto_tokens_lem'].apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words com e sem lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    opo_texto_tokens  \\\n",
       "0  [gender, 2021, caption, interviewing, communit...   \n",
       "1  [department, scientific, technological, policy...   \n",
       "2  [vacancy, graduates, technical, course, studen...   \n",
       "3  [scholarship, lasts, two, years, renewed, anot...   \n",
       "4  [registration, open, selection, one, 01, schol...   \n",
       "5  [technical, training, scholarship, level, iv, ...   \n",
       "6  [candidate, desired, skills, experience, molec...   \n",
       "7  [prerequisites, graduation, biology, zootechni...   \n",
       "8  [consultancy, specialized, application, develo...   \n",
       "9  [collaborative, project, within, department, b...   \n",
       "\n",
       "                                       opo_texto_bow  \\\n",
       "0  {'gender': 1, '2021': 4, 'caption': 1, 'interv...   \n",
       "1  {'department': 1, 'scientific': 1, 'technologi...   \n",
       "2  {'vacancy': 1, 'graduates': 1, 'technical': 1,...   \n",
       "3  {'scholarship': 4, 'lasts': 1, 'two': 1, 'year...   \n",
       "4  {'registration': 2, 'open': 1, 'selection': 1,...   \n",
       "5  {'technical': 1, 'training': 1, 'scholarship':...   \n",
       "6  {'candidate': 1, 'desired': 2, 'skills': 1, 'e...   \n",
       "7  {'prerequisites': 1, 'graduation': 1, 'biology...   \n",
       "8  {'consultancy': 1, 'specialized': 1, 'applicat...   \n",
       "9  {'collaborative': 1, 'project': 1, 'within': 1...   \n",
       "\n",
       "                                   opo_texto_bow_lem  \n",
       "0  {'gender': 1, '2021': 4, 'caption': 1, 'interv...  \n",
       "1  {'department': 1, 'scientific': 1, 'technologi...  \n",
       "2  {'vacancy': 1, 'graduate': 1, 'technical': 1, ...  \n",
       "3  {'scholarship': 4, 'last': 1, 'two': 1, 'year'...  \n",
       "4  {'registration': 3, 'open': 1, 'selection': 1,...  \n",
       "5  {'technical': 1, 'training': 1, 'scholarship':...  \n",
       "6  {'candidate': 1, 'desired': 2, 'skill': 1, 'ex...  \n",
       "7  {'prerequisite': 1, 'graduation': 1, 'biology'...  \n",
       "8  {'consultancy': 1, 'specialized': 1, 'applicat...  \n",
       "9  {'collaborative': 1, 'project': 1, 'within': 1...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto_tokens</th>\n      <th>opo_texto_bow</th>\n      <th>opo_texto_bow_lem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[gender, 2021, caption, interviewing, communit...</td>\n      <td>{'gender': 1, '2021': 4, 'caption': 1, 'interv...</td>\n      <td>{'gender': 1, '2021': 4, 'caption': 1, 'interv...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[department, scientific, technological, policy...</td>\n      <td>{'department': 1, 'scientific': 1, 'technologi...</td>\n      <td>{'department': 1, 'scientific': 1, 'technologi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[vacancy, graduates, technical, course, studen...</td>\n      <td>{'vacancy': 1, 'graduates': 1, 'technical': 1,...</td>\n      <td>{'vacancy': 1, 'graduate': 1, 'technical': 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n      <td>{'scholarship': 4, 'lasts': 1, 'two': 1, 'year...</td>\n      <td>{'scholarship': 4, 'last': 1, 'two': 1, 'year'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[registration, open, selection, one, 01, schol...</td>\n      <td>{'registration': 2, 'open': 1, 'selection': 1,...</td>\n      <td>{'registration': 3, 'open': 1, 'selection': 1,...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[technical, training, scholarship, level, iv, ...</td>\n      <td>{'technical': 1, 'training': 1, 'scholarship':...</td>\n      <td>{'technical': 1, 'training': 1, 'scholarship':...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[candidate, desired, skills, experience, molec...</td>\n      <td>{'candidate': 1, 'desired': 2, 'skills': 1, 'e...</td>\n      <td>{'candidate': 1, 'desired': 2, 'skill': 1, 'ex...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[prerequisites, graduation, biology, zootechni...</td>\n      <td>{'prerequisites': 1, 'graduation': 1, 'biology...</td>\n      <td>{'prerequisite': 1, 'graduation': 1, 'biology'...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[consultancy, specialized, application, develo...</td>\n      <td>{'consultancy': 1, 'specialized': 1, 'applicat...</td>\n      <td>{'consultancy': 1, 'specialized': 1, 'applicat...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[collaborative, project, within, department, b...</td>\n      <td>{'collaborative': 1, 'project': 1, 'within': 1...</td>\n      <td>{'collaborative': 1, 'project': 1, 'within': 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_texto_bow', 'opo_texto_bow_lem']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapeamento do Corpus em Dicionário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos passar a usar números para representar cada token, por meio da criação de um `dicionario_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dicionario_corpus = Dictionary(X['opo_texto_tokens'].tolist() + X['opo_texto_tokens_lem'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado do mapeamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dicionario do corpus:\n\n{'15': 0, '2021': 1, '22': 2, '238': 3, '30': 4, 'applications': 5, 'call': 6, 'caption': 7, 'closing': 8, 'community': 9, 'conservation': 10, 'consultant': 11, 'credit': 12, 'date': 13, 'develop': 14, 'development': 15, 'due': 16, 'engage': 17, 'english': 18, 'gender': 19, 'guidance': 20, 'information': 21, 'innovative': 22, 'intends': 23, 'interviewing': 24, 'kb': 25, 'knowledge': 26, 'march': 27, 'member': 28, 'net': 29, 'opening': 30, 'overview': 31, 'pertaining': 32, 'product': 33, 'proposals': 34, 'provide': 35, 'questions': 36, 'sent': 37, 'strengthen': 38, 'strengthening': 39, 'submissions': 40, 'voices': 41, 'women': 42, '1': 43, '10': 44, '2': 45, '202': 46, '3': 47, '373': 48, '378': 49, '4': 50, '5': 51, '553': 52, '6230': 53, '7': 54, 'activity': 55, 'amount': 56, 'announces': 57, 'annual': 58, 'application': 59, 'available': 60, 'based': 61, 'big': 62, 'br': 63, 'calls': 64, 'catching': 65, 'chair': 66, 'communicate': 67, 'contact': 68, 'convergence': 69, 'data': 70, 'department': 71, 'design': 72, 'directly': 73, 'doctoral': 74, 'ecosystems': 75, 'electronically': 76, 'email': 77, 'en': 78, 'entrepreneurship': 79}\n...\n"
     ]
    }
   ],
   "source": [
    "print('Dicionario do corpus:\\n\\n',\n",
    "      {k: v for i, (k, v) in enumerate(dicionario_corpus.token2id.items()) if i < 80}, '\\n...', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de consulta ao dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "dicionario_corpus.token2id['grant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'governance'"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "dicionario_corpus.get(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words com Dicionário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar duas novas colunas fazendo `bag of words` de pares de inteiros para o texto normal e para o lematizado.\n",
    "O primeiro elemento deste par é o `id` do token no `dicionario_corpus` e o segundo elemento é a contagem de ocorrências deste token no documento.\n",
    "\n",
    "Estamos convencionando chamar as colunas inteiras de `'opo_int_...'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos bag of words para o texto normal e lematizado\n",
    "X['opo_int_bow'] = X['opo_texto_tokens'].apply(dicionario_corpus.doc2bow)\n",
    "X['opo_int_bow_lem'] = X['opo_texto_tokens_lem'].apply(dicionario_corpus.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos bag of words após mapeamento em dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     opo_texto_tokens  \\\n",
       "0   [gender, 2021, caption, interviewing, communit...   \n",
       "1   [department, scientific, technological, policy...   \n",
       "2   [vacancy, graduates, technical, course, studen...   \n",
       "3   [scholarship, lasts, two, years, renewed, anot...   \n",
       "4   [registration, open, selection, one, 01, schol...   \n",
       "5   [technical, training, scholarship, level, iv, ...   \n",
       "6   [candidate, desired, skills, experience, molec...   \n",
       "7   [prerequisites, graduation, biology, zootechni...   \n",
       "8   [consultancy, specialized, application, develo...   \n",
       "9   [collaborative, project, within, department, b...   \n",
       "10  [multi, structural, crystallography, laborator...   \n",
       "11  [vacancy, postdoctoral, researcher, code, scho...   \n",
       "12  [opportunity, 1, level, three, technical, trai...   \n",
       "13  [research, innovation, biodiversity, pharmaceu...   \n",
       "14  [research, innovation, biodiversity, pharmaceu...   \n",
       "\n",
       "                                          opo_int_bow  \\\n",
       "0   [(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1...   \n",
       "1   [(1, 1), (6, 1), (21, 1), (43, 2), (44, 2), (4...   \n",
       "2   [(15, 1), (21, 2), (61, 3), (63, 1), (70, 2), ...   \n",
       "3   [(44, 3), (48, 1), (54, 1), (55, 1), (56, 1), ...   \n",
       "4   [(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...   \n",
       "5   [(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...   \n",
       "6   [(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...   \n",
       "7   [(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...   \n",
       "8   [(15, 1), (20, 1), (44, 1), (59, 1), (61, 1), ...   \n",
       "9   [(15, 1), (63, 2), (71, 1), (77, 1), (93, 1), ...   \n",
       "10  [(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...   \n",
       "11  [(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...   \n",
       "12  [(43, 1), (63, 2), (71, 1), (93, 1), (103, 1),...   \n",
       "13  [(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...   \n",
       "14  [(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...   \n",
       "\n",
       "                                      opo_int_bow_lem  \n",
       "0   [(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (6, 2...  \n",
       "1   [(1, 1), (6, 2), (21, 1), (43, 2), (44, 2), (4...  \n",
       "2   [(15, 1), (21, 2), (55, 1), (61, 3), (63, 1), ...  \n",
       "3   [(44, 3), (48, 1), (54, 1), (55, 3), (56, 1), ...  \n",
       "4   [(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...  \n",
       "5   [(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...  \n",
       "6   [(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...  \n",
       "7   [(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...  \n",
       "8   [(15, 1), (20, 1), (44, 1), (55, 1), (59, 1), ...  \n",
       "9   [(15, 1), (55, 1), (63, 2), (71, 1), (77, 1), ...  \n",
       "10  [(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...  \n",
       "11  [(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...  \n",
       "12  [(43, 1), (63, 2), (71, 1), (93, 1), (97, 2), ...  \n",
       "13  [(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...  \n",
       "14  [(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_texto_tokens</th>\n      <th>opo_int_bow</th>\n      <th>opo_int_bow_lem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[gender, 2021, caption, interviewing, communit...</td>\n      <td>[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n      <td>[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (6, 2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[department, scientific, technological, policy...</td>\n      <td>[(1, 1), (6, 1), (21, 1), (43, 2), (44, 2), (4...</td>\n      <td>[(1, 1), (6, 2), (21, 1), (43, 2), (44, 2), (4...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[vacancy, graduates, technical, course, studen...</td>\n      <td>[(15, 1), (21, 2), (61, 3), (63, 1), (70, 2), ...</td>\n      <td>[(15, 1), (21, 2), (55, 1), (61, 3), (63, 1), ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[scholarship, lasts, two, years, renewed, anot...</td>\n      <td>[(44, 3), (48, 1), (54, 1), (55, 1), (56, 1), ...</td>\n      <td>[(44, 3), (48, 1), (54, 1), (55, 3), (56, 1), ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[registration, open, selection, one, 01, schol...</td>\n      <td>[(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...</td>\n      <td>[(26, 1), (37, 2), (43, 2), (45, 2), (47, 3), ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[technical, training, scholarship, level, iv, ...</td>\n      <td>[(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...</td>\n      <td>[(15, 3), (60, 1), (63, 1), (124, 2), (132, 1)...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[candidate, desired, skills, experience, molec...</td>\n      <td>[(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...</td>\n      <td>[(18, 1), (26, 1), (44, 2), (47, 1), (48, 1), ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[prerequisites, graduation, biology, zootechni...</td>\n      <td>[(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...</td>\n      <td>[(26, 1), (63, 1), (70, 1), (124, 2), (140, 1)...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[consultancy, specialized, application, develo...</td>\n      <td>[(15, 1), (20, 1), (44, 1), (59, 1), (61, 1), ...</td>\n      <td>[(15, 1), (20, 1), (44, 1), (55, 1), (59, 1), ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[collaborative, project, within, department, b...</td>\n      <td>[(15, 1), (63, 2), (71, 1), (77, 1), (93, 1), ...</td>\n      <td>[(15, 1), (55, 1), (63, 2), (71, 1), (77, 1), ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[multi, structural, crystallography, laborator...</td>\n      <td>[(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...</td>\n      <td>[(18, 1), (30, 1), (43, 2), (44, 2), (45, 2), ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[vacancy, postdoctoral, researcher, code, scho...</td>\n      <td>[(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...</td>\n      <td>[(0, 1), (4, 1), (14, 1), (18, 2), (21, 1), (2...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[opportunity, 1, level, three, technical, trai...</td>\n      <td>[(43, 1), (63, 2), (71, 1), (93, 1), (103, 1),...</td>\n      <td>[(43, 1), (63, 2), (71, 1), (93, 1), (97, 2), ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[research, innovation, biodiversity, pharmaceu...</td>\n      <td>[(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...</td>\n      <td>[(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[research, innovation, biodiversity, pharmaceu...</td>\n      <td>[(1, 1), (5, 1), (14, 1), (15, 2), (30, 1), (4...</td>\n      <td>[(1, 1), (14, 1), (15, 2), (30, 1), (43, 1), (...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "X[['opo_texto_tokens', 'opo_int_bow', 'opo_int_bow_lem']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdif_palavras_mais_representativas(col_tfidf, dicionario, top=5):\n",
    "    palavras_mais_repr = []\n",
    "    for idx, tfidf_doc in enumerate(col_tfidf):\n",
    "        palavras =[]\n",
    "        # lista ordenada pelo peso tfidf do termo\n",
    "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
    "\n",
    "        # lista no tamanho especificado\n",
    "        tfidf_desc_tam = tfidf_desc[:top]\n",
    "\n",
    "        # conversão dos tokenids para palavras\n",
    "        palavras = [(dicionario.get(tokenid), peso) for tokenid, peso in tfidf_desc_tam]\n",
    "        palavras_mais_repr.append({f'Palavra_Rank_{rank + 1}': palavras[rank] for rank in range(len(palavras))})\n",
    "\n",
    "    return pd.DataFrame(palavras_mais_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_tfidf_mais_representativos(serie_int_bow, tam=10):\n",
    "    \"\"\"Gera um dataframe com os dados de tfidf\n",
    "    para os `tam` tokens mais representativos de cada documento\"\"\"\n",
    "    \n",
    "    corpus = serie_int_bow.to_list()\n",
    "    tfidf = TfidfModel(corpus=corpus)\n",
    "    \n",
    "    tfidf_docs = []\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        tfidf_doc = tfidf[doc]\n",
    "    \n",
    "        # lista ordenada pelo peso tfidf do termo\n",
    "        tfidf_desc = sorted(tfidf_doc, key=lambda termo: termo[1], reverse=True)\n",
    "\n",
    "        # lista no tamanho especificado\n",
    "        tfidf_desc_tam = tfidf_desc[:tam]\n",
    "\n",
    "        tfidf_docs.append({f'tdidf_desc_tam_{tam}': tfidf_desc_tam})\n",
    "        \n",
    "    return pd.DataFrame(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera colunas com os tfidfs para cada documento\n",
    "X['opo_int_tfidf'] = gera_tfidf_mais_representativos(X['opo_int_bow'], tam=30)\n",
    "X['opo_int_tfidf_lem'] = gera_tfidf_mais_representativos(X['opo_int_bow_lem'], tam=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado do TF-IDF para o corpus normal e o lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       opo_int_tfidf  \\\n",
       "0  [(41, 0.36756587588835876), (33, 0.33520330695...   \n",
       "1  [(128, 0.34398110623892564), (92, 0.3060948373...   \n",
       "2  [(164, 0.45424157947496496), (198, 0.287162733...   \n",
       "3  [(259, 0.25464027448556886), (124, 0.191327449...   \n",
       "\n",
       "                                   opo_int_tfidf_lem  \n",
       "0  [(5064, 0.38837366192956346), (33, 0.311098952...  \n",
       "1  [(128, 0.3581655100099124), (92, 0.31421016951...  \n",
       "2  [(164, 0.4642261881533202), (198, 0.2934748096...  \n",
       "3  [(259, 0.26564610890151963), (226, 0.179891246...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opo_int_tfidf</th>\n      <th>opo_int_tfidf_lem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[(41, 0.36756587588835876), (33, 0.33520330695...</td>\n      <td>[(5064, 0.38837366192956346), (33, 0.311098952...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[(128, 0.34398110623892564), (92, 0.3060948373...</td>\n      <td>[(128, 0.3581655100099124), (92, 0.31421016951...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[(164, 0.45424157947496496), (198, 0.287162733...</td>\n      <td>[(164, 0.4642261881533202), (198, 0.2934748096...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[(259, 0.25464027448556886), (124, 0.191327449...</td>\n      <td>[(259, 0.26564610890151963), (226, 0.179891246...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "X[['opo_int_tfidf', 'opo_int_tfidf_lem']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando as palavras mais importantes por documento, segundo seu TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      Palavra_Rank_1                        Palavra_Rank_2  \\\n",
       "0       (voice, 0.38837366192956346)         (product, 0.3110989527314427)   \n",
       "1         (spec, 0.3581655100099124)      (innovation, 0.3142101695125779)   \n",
       "2         (fish, 0.4642261881533202)  (slaughterhouse, 0.2934748096072516)   \n",
       "3  (philosophy, 0.26564610890151963)        (chapter, 0.17989124683007748)   \n",
       "4   (computing, 0.41388045847819366)          (30982, 0.19815141229263444)   \n",
       "5           (iv, 0.3744760568493732)            (back, 0.2907742650502568)   \n",
       "\n",
       "                       Palavra_Rank_3                      Palavra_Rank_4  \\\n",
       "0  (conservation, 0.2827228125679771)          (238, 0.22341486140644695)   \n",
       "1  (technological, 0.249367733120263)       (policy, 0.17954866829290167)   \n",
       "2        (trader, 0.2934748096072516)  (mathematical, 0.1659341820794618)   \n",
       "3   (specifying, 0.17989124683007748)      (studied, 0.17989124683007748)   \n",
       "4     (updating, 0.19815141229263444)   (scholarship, 0.1904302283248926)   \n",
       "5   (proficient, 0.21326815311297048)    (prototype, 0.21326815311297048)   \n",
       "\n",
       "                       Palavra_Rank_5                       Palavra_Rank_6  \\\n",
       "0      (caption, 0.22341486140644695)  (interviewing, 0.22341486140644695)   \n",
       "1           (202, 0.1790827550049562)            (378, 0.1790827550049562)   \n",
       "2     (industry, 0.15583535627011538)       (agrarian, 0.1467374048036258)   \n",
       "3        (table, 0.17989124683007748)    (translated, 0.17989124683007748)   \n",
       "4           (br, 0.17245963182909174)     (automation, 0.1722284478394696)   \n",
       "5  (refactoring, 0.21326815311297048)    (scheduling, 0.21326815311297048)   \n",
       "\n",
       "                       Palavra_Rank_7                  Palavra_Rank_8  \n",
       "0       (credit, 0.19418683096478173)   (engage, 0.19418683096478173)  \n",
       "1           (553, 0.1790827550049562)      (6230, 0.1790827550049562)  \n",
       "2  (codification, 0.1467374048036258)    (debate, 0.1467374048036258)  \n",
       "3    (variation, 0.17989124683007748)  (required, 0.1775346207759335)  \n",
       "4       (diploma, 0.1722284478394696)    (script, 0.1722284478394696)  \n",
       "5        (press, 0.18536755584659836)     (rest, 0.18536755584659836)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Palavra_Rank_1</th>\n      <th>Palavra_Rank_2</th>\n      <th>Palavra_Rank_3</th>\n      <th>Palavra_Rank_4</th>\n      <th>Palavra_Rank_5</th>\n      <th>Palavra_Rank_6</th>\n      <th>Palavra_Rank_7</th>\n      <th>Palavra_Rank_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(voice, 0.38837366192956346)</td>\n      <td>(product, 0.3110989527314427)</td>\n      <td>(conservation, 0.2827228125679771)</td>\n      <td>(238, 0.22341486140644695)</td>\n      <td>(caption, 0.22341486140644695)</td>\n      <td>(interviewing, 0.22341486140644695)</td>\n      <td>(credit, 0.19418683096478173)</td>\n      <td>(engage, 0.19418683096478173)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(spec, 0.3581655100099124)</td>\n      <td>(innovation, 0.3142101695125779)</td>\n      <td>(technological, 0.249367733120263)</td>\n      <td>(policy, 0.17954866829290167)</td>\n      <td>(202, 0.1790827550049562)</td>\n      <td>(378, 0.1790827550049562)</td>\n      <td>(553, 0.1790827550049562)</td>\n      <td>(6230, 0.1790827550049562)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(fish, 0.4642261881533202)</td>\n      <td>(slaughterhouse, 0.2934748096072516)</td>\n      <td>(trader, 0.2934748096072516)</td>\n      <td>(mathematical, 0.1659341820794618)</td>\n      <td>(industry, 0.15583535627011538)</td>\n      <td>(agrarian, 0.1467374048036258)</td>\n      <td>(codification, 0.1467374048036258)</td>\n      <td>(debate, 0.1467374048036258)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(philosophy, 0.26564610890151963)</td>\n      <td>(chapter, 0.17989124683007748)</td>\n      <td>(specifying, 0.17989124683007748)</td>\n      <td>(studied, 0.17989124683007748)</td>\n      <td>(table, 0.17989124683007748)</td>\n      <td>(translated, 0.17989124683007748)</td>\n      <td>(variation, 0.17989124683007748)</td>\n      <td>(required, 0.1775346207759335)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(computing, 0.41388045847819366)</td>\n      <td>(30982, 0.19815141229263444)</td>\n      <td>(updating, 0.19815141229263444)</td>\n      <td>(scholarship, 0.1904302283248926)</td>\n      <td>(br, 0.17245963182909174)</td>\n      <td>(automation, 0.1722284478394696)</td>\n      <td>(diploma, 0.1722284478394696)</td>\n      <td>(script, 0.1722284478394696)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(iv, 0.3744760568493732)</td>\n      <td>(back, 0.2907742650502568)</td>\n      <td>(proficient, 0.21326815311297048)</td>\n      <td>(prototype, 0.21326815311297048)</td>\n      <td>(refactoring, 0.21326815311297048)</td>\n      <td>(scheduling, 0.21326815311297048)</td>\n      <td>(press, 0.18536755584659836)</td>\n      <td>(rest, 0.18536755584659836)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "tfdif_palavras_mais_representativas(X['opo_int_tfidf_lem'], dicionario_corpus, top=8).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de Treinamento e de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['00', '000', '001', '01', '012', '018', '019', '02', '025', '03', '04', '040', '05', '057', '06', '0663', '07', '08', '09', '093', '10', '100', '104', '11', '110', '113', '12', '120', '12120', '123', '125', '12549', '12689', '129', '13', '131', '14', '140', '148', '15', '150', '151', '153', '16', '165', '17', '17th', '18', '180', '189']\n[[0.         0.02316647 0.         ... 0.         0.         0.        ]\n [0.         0.00924536 0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]\n ...\n [0.08391568 0.01646339 0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           00       000  001   01  012  018  019   02  025   03  ...  \\\n",
       "0    0.000000  0.023166  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1    0.000000  0.009245  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2    0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3    0.018653  0.027752  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4    0.000000  0.015230  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "..        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "129  0.000000  0.039211  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "130  0.018948  0.036245  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "131  0.000000  0.056008  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "132  0.000000  0.014802  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "133  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       yearly     years  yen  yields  york     young  youth   yr  zone  \\\n",
       "0    0.000000  0.015444  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "1    0.026855  0.018491  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "2    0.000000  0.000000  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "3    0.000000  0.011894  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "4    0.000000  0.030460  0.0     0.0   0.0  0.027722    0.0  0.0   0.0   \n",
       "..        ...       ...  ...     ...   ...       ...    ...  ...   ...   \n",
       "129  0.000000  0.000000  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "130  0.000000  0.000000  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "131  0.000000  0.037339  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "132  0.000000  0.044405  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "133  0.000000  0.027704  0.0     0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "\n",
       "     zootechnics  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "..           ...  \n",
       "129          0.0  \n",
       "130          0.0  \n",
       "131          0.0  \n",
       "132          0.0  \n",
       "133          0.0  \n",
       "\n",
       "[134 rows x 4340 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>001</th>\n      <th>01</th>\n      <th>012</th>\n      <th>018</th>\n      <th>019</th>\n      <th>02</th>\n      <th>025</th>\n      <th>03</th>\n      <th>...</th>\n      <th>yearly</th>\n      <th>years</th>\n      <th>yen</th>\n      <th>yields</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youth</th>\n      <th>yr</th>\n      <th>zone</th>\n      <th>zootechnics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.023166</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.015444</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.009245</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.026855</td>\n      <td>0.018491</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.018653</td>\n      <td>0.027752</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.011894</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.015230</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.030460</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.027722</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>0.000000</td>\n      <td>0.039211</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>0.018948</td>\n      <td>0.036245</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>0.000000</td>\n      <td>0.056008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.037339</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>0.000000</td>\n      <td>0.014802</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.044405</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.027704</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>134 rows × 4340 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:50])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:15])\n",
    "\n",
    "# Create the CountVectorizer DataFrame: count_df\n",
    "#count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_resultado(y_test, y_pred):\n",
    "    print(f' Acurácia:\\t{100 * accuracy_score(y_test, y_pred):.2f} %')\n",
    "    print(\" Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred, labels=['N', 'Y']))\n",
    "    print(\" Relatório de classificação:\\n\", classification_report(y_test, y_pred, labels=['N', 'Y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X['opo_texto_sem_stop'], y, test_size=0.33)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X['opo_texto_sem_stop_lem'], y, stratify=y, test_size=0.25) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Distribuição de classes\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Treino  Teste  Treino%  Teste%\n",
       "clas       1      1    100.0   100.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treino</th>\n      <th>Teste</th>\n      <th>Treino%</th>\n      <th>Teste%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>clas</th>\n      <td>1</td>\n      <td>1</td>\n      <td>100.0</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "print('Distribuição de classes')\n",
    "dist_classes = pd.DataFrame({'Treino': dict(Counter(y_train)), 'Teste': dict(Counter(y_test))})\n",
    "dist_classes['Treino%'] = dist_classes['Treino'].div(dist_classes['Treino'].sum()).mul(100)\n",
    "dist_classes['Teste%'] = dist_classes['Teste'].div(dist_classes['Teste'].sum()).mul(100)\n",
    "# dist_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes com Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_bow_train = count_vectorizer.fit_transform(X_train)\n",
    "X_bow_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_NB_bow_alpha(alpha=1):\n",
    "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
    "    print(f'\\n{\"-\"*45}')\n",
    "    print(f'Naive Bayes - BoW')\n",
    "    print(f'{\"-\"*45}')\n",
    "    classificador_bow = MultinomialNB(alpha=alpha)\n",
    "    classificador_bow.fit(X_bow_train, y_train.values.ravel())\n",
    "    y_pred_bow = classificador_bow.predict(X_bow_test)\n",
    "    avalia_resultado(y_test, y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.01 0.21 0.41 0.61 0.81]\n\n---------------------------------------------\nNaive Bayes - BoW\n---------------------------------------------\n Acurácia:\t82.00 %\n Matriz de Confusão:\n [[15  3]\n [ 6 26]]\n Relatório de classificação:\n               precision    recall  f1-score   support\n\n           N       0.71      0.83      0.77        18\n           Y       0.90      0.81      0.85        32\n\n    accuracy                           0.82        50\n   macro avg       0.81      0.82      0.81        50\nweighted avg       0.83      0.82      0.82        50\n\n\n---------------------------------------------\nNaive Bayes - BoW\n---------------------------------------------\n Acurácia:\t78.00 %\n Matriz de Confusão:\n [[17  1]\n [10 22]]\n Relatório de classificação:\n               precision    recall  f1-score   support\n\n           N       0.63      0.94      0.76        18\n           Y       0.96      0.69      0.80        32\n\n    accuracy                           0.78        50\n   macro avg       0.79      0.82      0.78        50\nweighted avg       0.84      0.78      0.78        50\n\n\n---------------------------------------------\nNaive Bayes - BoW\n---------------------------------------------\n Acurácia:\t76.00 %\n Matriz de Confusão:\n [[17  1]\n [11 21]]\n Relatório de classificação:\n               precision    recall  f1-score   support\n\n           N       0.61      0.94      0.74        18\n           Y       0.95      0.66      0.78        32\n\n    accuracy                           0.76        50\n   macro avg       0.78      0.80      0.76        50\nweighted avg       0.83      0.76      0.76        50\n\n\n---------------------------------------------\nNaive Bayes - BoW\n---------------------------------------------\n Acurácia:\t76.00 %\n Matriz de Confusão:\n [[17  1]\n [11 21]]\n Relatório de classificação:\n               precision    recall  f1-score   support\n\n           N       0.61      0.94      0.74        18\n           Y       0.95      0.66      0.78        32\n\n    accuracy                           0.76        50\n   macro avg       0.78      0.80      0.76        50\nweighted avg       0.83      0.76      0.76        50\n\n\n---------------------------------------------\nNaive Bayes - BoW\n---------------------------------------------\n Acurácia:\t76.00 %\n Matriz de Confusão:\n [[17  1]\n [11 21]]\n Relatório de classificação:\n               precision    recall  f1-score   support\n\n           N       0.61      0.94      0.74        18\n           Y       0.95      0.66      0.78        32\n\n    accuracy                           0.76        50\n   macro avg       0.78      0.80      0.76        50\nweighted avg       0.83      0.76      0.76        50\n\n"
     ]
    }
   ],
   "source": [
    "# Varia o parâmetro alpha para checar qual o melhor\r\n",
    "alphas = np.arange(0.01, 1, 0.2)\r\n",
    "for alpha in alphas:\r\n",
    "    classifica_NB_bow_alpha(alpha=alpha)\r\n",
    "    # 0.01, 0.21, 0.41, 0.61, 0.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes com TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_NB_tfidf_alpha(alpha, verb=True):\n",
    "    \"\"\"Classifica TF-DF para diferentes valores de alpha\"\"\"\n",
    "    print(f'\\n{\"-\"*55}')\n",
    "    print(f'Naive Bayes - TF-IDF')\n",
    "    print(f'{\"-\"*55}\\nAlpha = {alpha:.2f}:\\n{\"-\"*55}')\n",
    "    classificador_tfidf = MultinomialNB(alpha=alpha)\n",
    "    classificador_tfidf.fit(X_tfidf_train, y_train.values.ravel())\n",
    "    y_pred_tfidf = classificador_tfidf.predict(X_tfidf_test)\n",
    "    if verb:\n",
    "        avalia_resultado(y_test, y_pred_tfidf)\n",
    "    \n",
    "    return classificador_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.01, 0.21, 0.41, 0.61, 0.81])"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "# Varia o parâmetro alpha para checar qual o melhor\n",
    "alphas = np.arange(0.01, 1, 0.2)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.01:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t86.00 %\n",
      " Matriz de Confusão:\n",
      " [[15  3]\n",
      " [ 4 28]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.83      0.81        18\n",
      "           Y       0.90      0.88      0.89        32\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.85      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.21:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t76.00 %\n",
      " Matriz de Confusão:\n",
      " [[11  7]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.69      0.61      0.65        18\n",
      "           Y       0.79      0.84      0.82        32\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.74      0.73      0.73        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.41:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 9  9]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.50      0.67        18\n",
      "           Y       0.78      1.00      0.88        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.89      0.75      0.77        50\n",
      "weighted avg       0.86      0.82      0.80        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.61:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t80.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 8 10]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.44      0.62        18\n",
      "           Y       0.76      1.00      0.86        32\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.88      0.72      0.74        50\n",
      "weighted avg       0.85      0.80      0.78        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.81:\n",
      "-------------------------------------------------------\n",
      " Acurácia:\t76.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 6 12]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.33      0.50        18\n",
      "           Y       0.73      1.00      0.84        32\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.86      0.67      0.67        50\n",
      "weighted avg       0.83      0.76      0.72        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    classifica_NB_tfidf_alpha(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "Naive Bayes - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Alpha = 0.01:\n",
      "-------------------------------------------------------\n",
      "N:\n",
      "[(-11.491381210629868, '09'), (-11.491381210629868, '127'), (-11.491381210629868, '129'), (-11.491381210629868, '17th'), (-11.491381210629868, '20211'), (-11.491381210629868, '202117'), (-11.491381210629868, '202122'), (-11.491381210629868, '20222021'), (-11.491381210629868, '2030'), (-11.491381210629868, '222'), (-11.491381210629868, '2329'), (-11.491381210629868, '238'), (-11.491381210629868, '250'), (-11.491381210629868, '354'), (-11.491381210629868, '371')]\n",
      "\n",
      "Y:\n",
      "[(-5.706052659827187, 'acceptance'), (-5.6530697358048325, 'grant'), (-5.615985102368938, 'letter'), (-5.5612565809041214, 'country'), (-5.557736143665154, 'science'), (-5.540016450905657, 'organisation'), (-5.531964545281696, 'year'), (-5.521393413465941, 'br'), (-5.484795388809013, 'project'), (-5.314406280219622, 'scholarship'), (-5.166337877281388, 'twas'), (-5.06910641238818, 'application'), (-5.0433389529830635, 'fellowship'), (-4.9880901734051095, 'cost'), (-4.767839060590731, 'research')]\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Extraindo as características do melhor modelo\n",
    "# alpha foi 0.01\n",
    "nb_classifier = classifica_NB_tfidf_alpha(alpha=0.01, verb=False)\n",
    "\n",
    "labels = nb_classifier.classes_\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "print(f'{labels[0]}:\\n{feat_with_weights[:15]}')\n",
    "print(f'\\n{labels[1]}:\\n{feat_with_weights[-15:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_svn = ['linear', 'rbf', 'sigmoid']\n",
    "C = [0.1, 0.3, 0.6, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_svm(descricao, tipo, X_train, y_train, X_test, y_test, C):\n",
    "    print(f'\\n{\"-\"*55}\\nSVM - {descricao}\\n{\"-\"*55}')\n",
    "    print(f'Kernel = {tipo}, C = {C}\\n')\n",
    "    clf = SVC(kernel=tipo, C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    avalia_resultado(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.1\n",
      "\n",
      " Acurácia:\t78.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.67      0.69        18\n",
      "           Y       0.82      0.84      0.83        32\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.3\n",
      "\n",
      " Acurácia:\t78.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.67      0.69        18\n",
      "           Y       0.82      0.84      0.83        32\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.6\n",
      "\n",
      " Acurácia:\t78.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.67      0.69        18\n",
      "           Y       0.82      0.84      0.83        32\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.8\n",
      "\n",
      " Acurácia:\t78.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.67      0.69        18\n",
      "           Y       0.82      0.84      0.83        32\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.1\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.3\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.6\n",
      "\n",
      " Acurácia:\t68.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 2 16]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.11      0.20        18\n",
      "           Y       0.67      1.00      0.80        32\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.83      0.56      0.50        50\n",
      "weighted avg       0.79      0.68      0.58        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.8\n",
      "\n",
      " Acurácia:\t70.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 5 13]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.28      0.40        18\n",
      "           Y       0.70      0.94      0.80        32\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.71      0.61      0.60        50\n",
      "weighted avg       0.70      0.70      0.66        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.1\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.3\n",
      "\n",
      " Acurácia:\t60.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.62      0.94      0.75        32\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.31      0.47      0.38        50\n",
      "weighted avg       0.40      0.60      0.48        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.6\n",
      "\n",
      " Acurácia:\t60.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.62      0.94      0.75        32\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.31      0.47      0.38        50\n",
      "weighted avg       0.40      0.60      0.48        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - Bag of Words\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.8\n",
      "\n",
      " Acurácia:\t60.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.62      0.94      0.75        32\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.31      0.47      0.38        50\n",
      "weighted avg       0.40      0.60      0.48        50\n",
      "\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for tipo in tipos_svn:\n",
    "    for c in C:\n",
    "        avalia_svm(\"Bag of Words\", tipo, X_bow_train, y_train.values.ravel(), X_bow_test, y_test, C=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.1\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.3\n",
      "\n",
      " Acurácia:\t68.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 2 16]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.11      0.20        18\n",
      "           Y       0.67      1.00      0.80        32\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.83      0.56      0.50        50\n",
      "weighted avg       0.79      0.68      0.58        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.6\n",
      "\n",
      " Acurácia:\t72.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 6 12]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.75      0.33      0.46        18\n",
      "           Y       0.71      0.94      0.81        32\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.73      0.64      0.64        50\n",
      "weighted avg       0.73      0.72      0.69        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = linear, C = 0.8\n",
      "\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.80      0.67      0.73        18\n",
      "           Y       0.83      0.91      0.87        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.81      0.79      0.80        50\n",
      "weighted avg       0.82      0.82      0.82        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.1\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.3\n",
      "\n",
      " Acurácia:\t68.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 2 16]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.11      0.20        18\n",
      "           Y       0.67      1.00      0.80        32\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.83      0.56      0.50        50\n",
      "weighted avg       0.79      0.68      0.58        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.6\n",
      "\n",
      " Acurácia:\t72.00 %\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " Matriz de Confusão:\n",
      " [[ 5 13]\n",
      " [ 1 31]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.28      0.42        18\n",
      "           Y       0.70      0.97      0.82        32\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.77      0.62      0.62        50\n",
      "weighted avg       0.75      0.72      0.67        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = rbf, C = 0.8\n",
      "\n",
      " Acurácia:\t70.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 6 12]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.67      0.33      0.44        18\n",
      "           Y       0.71      0.91      0.79        32\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.69      0.62      0.62        50\n",
      "weighted avg       0.69      0.70      0.67        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.1\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.3\n",
      "\n",
      " Acurácia:\t64.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 0 18]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        18\n",
      "           Y       0.64      1.00      0.78        32\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.32      0.50      0.39        50\n",
      "weighted avg       0.41      0.64      0.50        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.6\n",
      "\n",
      " Acurácia:\t74.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 5 13]\n",
      " [ 0 32]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.28      0.43        18\n",
      "           Y       0.71      1.00      0.83        32\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.86      0.64      0.63        50\n",
      "weighted avg       0.82      0.74      0.69        50\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "SVM - TF-IDF\n",
      "-------------------------------------------------------\n",
      "Kernel = sigmoid, C = 0.8\n",
      "\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[10  8]\n",
      " [ 1 31]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.91      0.56      0.69        18\n",
      "           Y       0.79      0.97      0.87        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.85      0.76      0.78        50\n",
      "weighted avg       0.84      0.82      0.81        50\n",
      "\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bolin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for tipo in tipos_svn:\n",
    "    for c in C:\n",
    "        avalia_svm(\"TF-IDF\", tipo, X_tfidf_train, y_train.values.ravel(), X_tfidf_test,y_test, C=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimadores = [5, 10, 100, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_random_forest(descricao, X_train, y_train, X_test, n_est):\n",
    "    print(f'\\n{\"-\"*60}\\nRandom Forest - {descricao}\\n{\"-\"*60}')\n",
    "    print(f'No estimadores = {n_est}\\n')\n",
    "    classifier = RandomForestClassifier(n_estimators=n_est)\n",
    "    classifier.fit(X_train, y_train) \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    avalia_resultado(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 5\n",
      "\n",
      " Acurácia:\t68.00 %\n",
      " Matriz de Confusão:\n",
      " [[ 6 12]\n",
      " [ 4 28]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.60      0.33      0.43        18\n",
      "           Y       0.70      0.88      0.78        32\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.65      0.60      0.60        50\n",
      "weighted avg       0.66      0.68      0.65        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 10\n",
      "\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[14  4]\n",
      " [ 5 27]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.78      0.76        18\n",
      "           Y       0.87      0.84      0.86        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.80      0.81      0.81        50\n",
      "weighted avg       0.82      0.82      0.82        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 100\n",
      "\n",
      " Acurácia:\t80.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 4 28]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.75      0.67      0.71        18\n",
      "           Y       0.82      0.88      0.85        32\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.79      0.77      0.78        50\n",
      "weighted avg       0.80      0.80      0.80        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 500\n",
      "\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.80      0.67      0.73        18\n",
      "           Y       0.83      0.91      0.87        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.81      0.79      0.80        50\n",
      "weighted avg       0.82      0.82      0.82        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 1000\n",
      "\n",
      " Acurácia:\t80.00 %\n",
      " Matriz de Confusão:\n",
      " [[11  7]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.61      0.69        18\n",
      "           Y       0.81      0.91      0.85        32\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.76      0.77        50\n",
      "weighted avg       0.80      0.80      0.79        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_est in n_estimadores:\n",
    "    avalia_random_forest('BoW', X_bow_train, y_train.values.ravel(), X_bow_test, n_est=n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest -TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 5\n",
      "\n",
      " Acurácia:\t72.00 %\n",
      " Matriz de Confusão:\n",
      " [[11  7]\n",
      " [ 7 25]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.61      0.61      0.61        18\n",
      "           Y       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.70      0.70      0.70        50\n",
      "weighted avg       0.72      0.72      0.72        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 10\n",
      "\n",
      " Acurácia:\t82.00 %\n",
      " Matriz de Confusão:\n",
      " [[13  5]\n",
      " [ 4 28]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.72      0.74        18\n",
      "           Y       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.81      0.80      0.80        50\n",
      "weighted avg       0.82      0.82      0.82        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 100\n",
      "\n",
      " Acurácia:\t84.00 %\n",
      " Matriz de Confusão:\n",
      " [[12  6]\n",
      " [ 2 30]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.67      0.75        18\n",
      "           Y       0.83      0.94      0.88        32\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.80      0.82        50\n",
      "weighted avg       0.84      0.84      0.83        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 500\n",
      "\n",
      " Acurácia:\t78.00 %\n",
      " Matriz de Confusão:\n",
      " [[10  8]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.56      0.65        18\n",
      "           Y       0.78      0.91      0.84        32\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.73      0.74        50\n",
      "weighted avg       0.78      0.78      0.77        50\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest - BoW\n",
      "------------------------------------------------------------\n",
      "No estimadores = 1000\n",
      "\n",
      " Acurácia:\t80.00 %\n",
      " Matriz de Confusão:\n",
      " [[11  7]\n",
      " [ 3 29]]\n",
      " Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.79      0.61      0.69        18\n",
      "           Y       0.81      0.91      0.85        32\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.76      0.77        50\n",
      "weighted avg       0.80      0.80      0.79        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_est in n_estimadores:\n",
    "    avalia_random_forest('BoW', X_tfidf_train, y_train.values.ravel(), X_tfidf_test, n_est=n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MultinomialNB(alpha=0.01)\n",
      "Média: 0.79 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.21)\n",
      "Média: 0.76 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.41)\n",
      "Média: 0.75 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.61)\n",
      "Média: 0.75 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.81)\n",
      "Média: 0.75 | Desvio: 0.24\n",
      "SVC(C=0.1, kernel='linear')\n",
      "Média: 0.78 | Desvio: 0.23\n",
      "SVC(C=0.3, kernel='linear')\n",
      "Média: 0.77 | Desvio: 0.23\n",
      "SVC(C=0.6, kernel='linear')\n",
      "Média: 0.77 | Desvio: 0.23\n",
      "SVC(C=0.8, kernel='linear')\n",
      "Média: 0.77 | Desvio: 0.23\n",
      "SVC(C=0.1)\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.3)\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.6)\n",
      "Média: 0.65 | Desvio: 0.079\n",
      "SVC(C=0.8)\n",
      "Média: 0.68 | Desvio: 0.15\n",
      "SVC(C=0.1, kernel='sigmoid')\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.3, kernel='sigmoid')\n",
      "Média: 0.61 | Desvio: 0.14\n",
      "SVC(C=0.6, kernel='sigmoid')\n",
      "Média: 0.6 | Desvio: 0.15\n",
      "SVC(C=0.8, kernel='sigmoid')\n",
      "Média: 0.59 | Desvio: 0.14\n",
      "RandomForestClassifier(n_estimators=5)\n",
      "Média: 0.78 | Desvio: 0.2\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "Média: 0.79 | Desvio: 0.22\n",
      "RandomForestClassifier()\n",
      "Média: 0.81 | Desvio: 0.22\n",
      "RandomForestClassifier(n_estimators=500)\n",
      "Média: 0.79 | Desvio: 0.22\n",
      "RandomForestClassifier(n_estimators=1000)\n",
      "Média: 0.79 | Desvio: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "models = [MultinomialNB(alpha=0.01), # 0.01, 0.21, 0.41, 0.61, 0.81\n",
    "MultinomialNB(alpha=0.21),MultinomialNB(alpha=0.41),MultinomialNB(alpha=0.61),MultinomialNB(alpha=0.81),\n",
    "# tipos_svn = ['linear', 'rbf', 'sigmoid'] C = [0.1, 0.3, 0.6, 0.8]\n",
    " SVC(kernel = 'linear', C = 0.1),SVC(kernel = 'linear', C = 0.3), SVC(kernel = 'linear', C = 0.6),SVC(kernel = 'linear', C = 0.8),\n",
    " SVC(kernel = 'rbf', C = 0.1),SVC(kernel = 'rbf', C = 0.3), SVC(kernel = 'rbf', C = 0.6),SVC(kernel = 'rbf', C = 0.8),\n",
    " SVC(kernel = 'sigmoid', C = 0.1),SVC(kernel = 'sigmoid', C = 0.3), SVC(kernel = 'sigmoid', C = 0.6),SVC(kernel = 'sigmoid', C = 0.8),\n",
    " #[5, 10, 100, 500, 1000]\n",
    "RandomForestClassifier(5),RandomForestClassifier(10),RandomForestClassifier(100),RandomForestClassifier(500),RandomForestClassifier(1000)]\n",
    "# score de cada modelo\n",
    "models_scores = []\n",
    "for model in models:\n",
    "    val_scores = cross_val_score(model, X_bow_train, y_train.values.ravel(), cv=50)\n",
    "    #nome_modelo = type(model).__name__ # somente para exibição\n",
    "    print(model)\n",
    "    #parametro_modelo=type(model).__kargs__\n",
    "    print('Média: {:.2} | Desvio: {:.2}'.format( np.mean(val_scores), np.std(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-Validation TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MultinomialNB(alpha=0.01)\n",
      "Média: 0.75 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.21)\n",
      "Média: 0.75 | Desvio: 0.25\n",
      "MultinomialNB(alpha=0.41)\n",
      "Média: 0.77 | Desvio: 0.24\n",
      "MultinomialNB(alpha=0.61)\n",
      "Média: 0.71 | Desvio: 0.21\n",
      "MultinomialNB(alpha=0.81)\n",
      "Média: 0.7 | Desvio: 0.19\n",
      "SVC(C=0.1, kernel='linear')\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.3, kernel='linear')\n",
      "Média: 0.68 | Desvio: 0.11\n",
      "SVC(C=0.6, kernel='linear')\n",
      "Média: 0.71 | Desvio: 0.23\n",
      "SVC(C=0.8, kernel='linear')\n",
      "Média: 0.77 | Desvio: 0.23\n",
      "SVC(C=0.1)\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.3)\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.6)\n",
      "Média: 0.68 | Desvio: 0.15\n",
      "SVC(C=0.8)\n",
      "Média: 0.73 | Desvio: 0.2\n",
      "SVC(C=0.1, kernel='sigmoid')\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.3, kernel='sigmoid')\n",
      "Média: 0.65 | Desvio: 0.065\n",
      "SVC(C=0.6, kernel='sigmoid')\n",
      "Média: 0.67 | Desvio: 0.24\n",
      "SVC(C=0.8, kernel='sigmoid')\n",
      "Média: 0.74 | Desvio: 0.23\n",
      "RandomForestClassifier(n_estimators=5)\n",
      "Média: 0.78 | Desvio: 0.2\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "Média: 0.77 | Desvio: 0.23\n",
      "RandomForestClassifier()\n",
      "Média: 0.77 | Desvio: 0.22\n",
      "RandomForestClassifier(n_estimators=500)\n",
      "Média: 0.77 | Desvio: 0.2\n",
      "RandomForestClassifier(n_estimators=1000)\n",
      "Média: 0.77 | Desvio: 0.2\n"
     ]
    }
   ],
   "source": [
    "models = [MultinomialNB(alpha=0.01), # 0.01, 0.21, 0.41, 0.61, 0.81\n",
    "MultinomialNB(alpha=0.21),MultinomialNB(alpha=0.41),MultinomialNB(alpha=0.61),MultinomialNB(alpha=0.81),\n",
    "# tipos_svn = ['linear', 'rbf', 'sigmoid'] C = [0.1, 0.3, 0.6, 0.8]\n",
    " SVC(kernel = 'linear', C = 0.1),SVC(kernel = 'linear', C = 0.3), SVC(kernel = 'linear', C = 0.6),SVC(kernel = 'linear', C = 0.8),\n",
    " SVC(kernel = 'rbf', C = 0.1),SVC(kernel = 'rbf', C = 0.3), SVC(kernel = 'rbf', C = 0.6),SVC(kernel = 'rbf', C = 0.8),\n",
    " SVC(kernel = 'sigmoid', C = 0.1),SVC(kernel = 'sigmoid', C = 0.3), SVC(kernel = 'sigmoid', C = 0.6),SVC(kernel = 'sigmoid', C = 0.8),\n",
    " #[5, 10, 100, 500, 1000]\n",
    "RandomForestClassifier(5),RandomForestClassifier(10),RandomForestClassifier(100),RandomForestClassifier(500),RandomForestClassifier(1000)]\n",
    "# score de cada modelo\n",
    "models_scores = []\n",
    "for model in models:\n",
    "    val_scores = cross_val_score(model, X_tfidf_train, y_train.values.ravel(), cv=50)\n",
    "    print(model)\n",
    "    #parametro_modelo=type(model).__kargs__\n",
    "    print('Média: {:.2} | Desvio: {:.2}'.format( np.mean(val_scores), np.std(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd0c9037d6a239f88f5dd1ffc6bf2fe80bb7a6b1100bd95b854bbbb5680e50c96da",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "c9037d6a239f88f5dd1ffc6bf2fe80bb7a6b1100bd95b854bbbb5680e50c96da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
